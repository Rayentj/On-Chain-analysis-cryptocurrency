{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feb9a7bf",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5930267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import time\n",
    "import requests\n",
    "\n",
    "# Import preprocessor from sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Model Metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Import cufflinks for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (20,10)\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Feature selection & Feature importance\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Time Series cross-validation\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Class encoder\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "# Models\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Import from keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.layers import Dropout, Dense, LSTM, SimpleRNN\n",
    "\n",
    "# Artificial Neural Nets\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38760cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set a seed value in order to make able to reproduce the results.\n",
    "seed_value = 100\n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "#import tensorflow as tf\n",
    "#tf.set_random_seed(seed_value)\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4f6a29",
   "metadata": {},
   "source": [
    "#  Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ba87b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_file(file_name):\n",
    "    api_key = \"2CPKEM22GvBVO87K9jQtPcReSzP\"\n",
    "    url = file_name + api_key\n",
    "    response = requests.get(url).text\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46b66daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_to_finaldata(name,base_url):\n",
    "    path='https://api.glassnode.com/v1/metrics/'+base_url+'?a=btc&api_key='\n",
    "    data=read_json_file(path)\n",
    "    pdObj = pd.read_json(data, orient='records',convert_dates=['t'])\n",
    "    \n",
    "    csvData = pdObj.to_csv(index=False)\n",
    "    if (name.upper()=='PRICE' and path=='https://api.glassnode.com/v1/metrics/market/price_usd_close?a=btc&api_key='):\n",
    "        \n",
    "        pdObj.to_csv('data/Data.csv', index=False)\n",
    "    \n",
    "    \n",
    "        # reading the CSV file\n",
    "        text = open('data/Data.csv', \"r\")\n",
    "  \n",
    "        #join() method combines all contents of \n",
    "        # csvfile.csv and formed as a string\n",
    "        text = ''.join([i for i in text]) \n",
    "  \n",
    "        # search and replace the contents\n",
    "        text = text.replace(\"t\", \"Datetime\") \n",
    "        text = text.replace(\"v\", name) \n",
    "\n",
    "  \n",
    "        # output.csv is the output file opened in write mode\n",
    "        x = open('data/Data.csv',\"w\")\n",
    "  \n",
    "        # all the replaced text is written in the output.csv file\n",
    "        x.writelines(text)\n",
    "        x.close()\n",
    "        \n",
    "       \n",
    "        \n",
    "    else:    \n",
    "        pdObj.to_csv('data/'+name + '.csv', index=False)\n",
    "    \n",
    "    \n",
    "        # reading the CSV file\n",
    "        text = open('data/'+name + '.csv', \"r\")\n",
    "  \n",
    "        #join() method combines all contents of \n",
    "        # csvfile.csv and formed as a string\n",
    "        text = ''.join([i for i in text]) \n",
    "  \n",
    "        # search and replace the contents\n",
    "        text = text.replace(\"t\", \"Datetime\") \n",
    "        text = text.replace(\"v\", name) \n",
    "\n",
    "  \n",
    "        # output.csv is the output file opened in write mode\n",
    "        x = open('data/'+name + '.csv',\"w\")\n",
    "  \n",
    "        # all the replaced text is written in the output.csv file\n",
    "        x.writelines(text)\n",
    "        x.close()\n",
    "        \n",
    "        data1=pd.read_table('data/Data.csv',sep=\",\")\n",
    "        data2=pd.read_table('data/'+name + '.csv',sep=\",\")\n",
    "        data1\n",
    "        \n",
    "        cols = data1.columns\n",
    "        \n",
    "        \n",
    "        for col in cols:\n",
    "            if (name in col):\n",
    "                \n",
    "                data1.drop([name], axis=1, inplace=True)\n",
    "                data1\n",
    "                data1.to_csv(\"data/Data.csv\", index = False)\n",
    "            else:\n",
    "                print(\"non\")  \n",
    "                \n",
    "        data=data1[data1[\"Datetime\"].isin(data2[\"Datetime\"])]\n",
    "        result = pd.merge(data,data2[[\"Datetime\",name]],on='Datetime', how='left')\n",
    "        result.to_csv(\"data/Data.csv\", index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1566a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non\n",
      "non\n",
      "non\n",
      "non\n",
      "non\n",
      "non\n",
      "non\n",
      "non\n",
      "non\n",
      "non\n",
      "non\n",
      "non\n",
      "non\n",
      "non\n",
      "non\n",
      "non\n",
      "non\n",
      "non\n",
      "non\n",
      "non\n",
      "non\n",
      "non\n",
      "non\n",
      "non\n",
      "non\n",
      "non\n",
      "non\n",
      "non\n",
      "non\n",
      "non\n",
      "non\n",
      "non\n",
      "non\n",
      "non\n",
      "non\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Stablecoin Supply Ratio SSR'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-f0a5f26c9f03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mapi_to_finaldata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Realized Profit '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'indicators/realized_profit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mapi_to_finaldata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Realized Loss'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'indicators/realized_loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mapi_to_finaldata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Stablecoin Supply Ratio SSR'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'indicators/ssr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mapi_to_finaldata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Net Unrealized Profit/Loss (NUPL) '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'indicators/net_unrealized_profit_loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mapi_to_finaldata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Relative Unrealized Profit'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'indicators/unrealized_profit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-36400ef50797>\u001b[0m in \u001b[0;36mapi_to_finaldata\u001b[1;34m(name, base_url)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Datetime\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Datetime\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Datetime\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Datetime'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/Data.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3028\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3029\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3030\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3032\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1266\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1314\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1316\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Stablecoin Supply Ratio SSR'] not in index\""
     ]
    }
   ],
   "source": [
    "\n",
    "api_to_finaldata('Price','market/price_usd_close')\n",
    "api_to_finaldata('Active Addresses','addresses/active_count')\n",
    "api_to_finaldata('New Addresses','addresses/new_non_zero_count')\n",
    "api_to_finaldata('NVT Ratio ','indicators/nvt')\n",
    "api_to_finaldata('NVT Signal','indicators/nvts')\n",
    "#api_to_finaldata('Velocity','indicators/velocityt')\n",
    "api_to_finaldata('Realized Profit ','indicators/realized_profit')\n",
    "api_to_finaldata('Realized Loss','indicators/realized_loss')\n",
    "api_to_finaldata('Stablecoin Supply Ratio SSR','indicators/ssr')\n",
    "api_to_finaldata('Net Unrealized Profit/Loss (NUPL) ','indicators/net_unrealized_profit_loss')\n",
    "api_to_finaldata('Relative Unrealized Profit','indicators/unrealized_profit')\n",
    "api_to_finaldata('Relative Unrealized Loss','indicators/unrealized_loss')\n",
    "\n",
    "\n",
    "\n",
    "api_to_finaldata('Total Addresses','addresses/count')\n",
    "api_to_finaldata('Sending Addresses','addresses/sending_count')\n",
    "api_to_finaldata('Receiving Addresses','addresses/receiving_count')\n",
    "api_to_finaldata('Inflation Rate ','supply/inflation_rate')\n",
    "api_to_finaldata('Balanced Price','indicators/balanced_price_usd')\n",
    "api_to_finaldata('Hash Ribbon','indicators/hash_ribbon')\n",
    "api_to_finaldata('Exchange Balance (Total) ','distribution/balance_exchanges')\n",
    "api_to_finaldata('Exchange Net Position Change','distribution/exchange_net_position_change')\n",
    "api_to_finaldata('Exchange Inflow Volume (Total)','transactions/transfers_volume_to_exchanges_sum')\n",
    "api_to_finaldata('Exchange Outflow Volume (Total) ','transactions/transfers_volume_from_exchanges_sum')\n",
    "api_to_finaldata('Inter-Exchange Volume','transactions/transfers_volume_between_exchanges_sum')\n",
    "api_to_finaldata('Inter-Exchange Transfers','transactions/transfers_between_exchanges_count')\n",
    "api_to_finaldata('MVRV','market/mvrv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0a2f8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Price</th>\n",
       "      <th>Active Addresses</th>\n",
       "      <th>New Addresses</th>\n",
       "      <th>NVT Ratio</th>\n",
       "      <th>NVT Signal</th>\n",
       "      <th>Velocity</th>\n",
       "      <th>Realized Profit</th>\n",
       "      <th>Realized Loss</th>\n",
       "      <th>Net_Unrealized_ProfitorLoss_(NUPL)</th>\n",
       "      <th>...</th>\n",
       "      <th>Receiving Addresses</th>\n",
       "      <th>Inflation Rate</th>\n",
       "      <th>Balanced Price</th>\n",
       "      <th>Exchange Balance (Total)</th>\n",
       "      <th>Exchange Net Position Change</th>\n",
       "      <th>Exchange Inflow Volume (Total)</th>\n",
       "      <th>Exchange Outflow Volume (Total)</th>\n",
       "      <th>Inter-Exchange Volume</th>\n",
       "      <th>Inter-Exchange Transfers</th>\n",
       "      <th>MVRV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-12-13</td>\n",
       "      <td>13.728511</td>\n",
       "      <td>45850</td>\n",
       "      <td>25807</td>\n",
       "      <td>2.800119</td>\n",
       "      <td>3.747164</td>\n",
       "      <td>0.357128</td>\n",
       "      <td>3.362596e+05</td>\n",
       "      <td>4.352469e+04</td>\n",
       "      <td>0.464531</td>\n",
       "      <td>...</td>\n",
       "      <td>34475</td>\n",
       "      <td>0.119919</td>\n",
       "      <td>6.031378</td>\n",
       "      <td>1.210780e+03</td>\n",
       "      <td>1006.364620</td>\n",
       "      <td>3963.202238</td>\n",
       "      <td>3646.982938</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>1</td>\n",
       "      <td>1.867095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-12-14</td>\n",
       "      <td>13.604543</td>\n",
       "      <td>41453</td>\n",
       "      <td>23215</td>\n",
       "      <td>3.696235</td>\n",
       "      <td>3.758553</td>\n",
       "      <td>0.270546</td>\n",
       "      <td>1.746492e+05</td>\n",
       "      <td>4.126883e+04</td>\n",
       "      <td>0.456186</td>\n",
       "      <td>...</td>\n",
       "      <td>31972</td>\n",
       "      <td>0.095951</td>\n",
       "      <td>6.043843</td>\n",
       "      <td>2.533150e+03</td>\n",
       "      <td>2177.125081</td>\n",
       "      <td>5517.487995</td>\n",
       "      <td>4195.092506</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.846665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-12-15</td>\n",
       "      <td>13.510539</td>\n",
       "      <td>34372</td>\n",
       "      <td>19291</td>\n",
       "      <td>6.595165</td>\n",
       "      <td>3.895515</td>\n",
       "      <td>0.151626</td>\n",
       "      <td>6.065564e+04</td>\n",
       "      <td>2.847964e+04</td>\n",
       "      <td>0.454525</td>\n",
       "      <td>...</td>\n",
       "      <td>27533</td>\n",
       "      <td>0.105433</td>\n",
       "      <td>6.048364</td>\n",
       "      <td>2.992707e+03</td>\n",
       "      <td>2107.685343</td>\n",
       "      <td>1795.413172</td>\n",
       "      <td>1335.838433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.832728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-12-16</td>\n",
       "      <td>13.395529</td>\n",
       "      <td>35514</td>\n",
       "      <td>19794</td>\n",
       "      <td>6.077174</td>\n",
       "      <td>4.022917</td>\n",
       "      <td>0.164550</td>\n",
       "      <td>9.175516e+04</td>\n",
       "      <td>3.742280e+04</td>\n",
       "      <td>0.447717</td>\n",
       "      <td>...</td>\n",
       "      <td>28438</td>\n",
       "      <td>0.100640</td>\n",
       "      <td>6.054062</td>\n",
       "      <td>3.060564e+03</td>\n",
       "      <td>2836.683769</td>\n",
       "      <td>2168.423522</td>\n",
       "      <td>2100.548977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.815466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-12-17</td>\n",
       "      <td>13.233350</td>\n",
       "      <td>40773</td>\n",
       "      <td>23932</td>\n",
       "      <td>6.177490</td>\n",
       "      <td>4.147675</td>\n",
       "      <td>0.161878</td>\n",
       "      <td>6.737691e+04</td>\n",
       "      <td>9.005393e+04</td>\n",
       "      <td>0.443454</td>\n",
       "      <td>...</td>\n",
       "      <td>33083</td>\n",
       "      <td>0.122683</td>\n",
       "      <td>6.053462</td>\n",
       "      <td>1.238189e+03</td>\n",
       "      <td>502.457143</td>\n",
       "      <td>4337.639201</td>\n",
       "      <td>6159.981340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.793560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142</th>\n",
       "      <td>2021-07-21</td>\n",
       "      <td>32131.635487</td>\n",
       "      <td>811197</td>\n",
       "      <td>366924</td>\n",
       "      <td>41.338808</td>\n",
       "      <td>21.936868</td>\n",
       "      <td>0.024190</td>\n",
       "      <td>3.961132e+08</td>\n",
       "      <td>3.665613e+08</td>\n",
       "      <td>0.398450</td>\n",
       "      <td>...</td>\n",
       "      <td>571527</td>\n",
       "      <td>0.017785</td>\n",
       "      <td>16172.892878</td>\n",
       "      <td>2.726084e+06</td>\n",
       "      <td>-8964.576554</td>\n",
       "      <td>39774.144754</td>\n",
       "      <td>42650.265681</td>\n",
       "      <td>12943.855953</td>\n",
       "      <td>5480</td>\n",
       "      <td>1.662858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3143</th>\n",
       "      <td>2021-07-22</td>\n",
       "      <td>32328.209838</td>\n",
       "      <td>802115</td>\n",
       "      <td>364808</td>\n",
       "      <td>56.976622</td>\n",
       "      <td>22.512967</td>\n",
       "      <td>0.017551</td>\n",
       "      <td>3.715456e+08</td>\n",
       "      <td>1.744004e+08</td>\n",
       "      <td>0.401763</td>\n",
       "      <td>...</td>\n",
       "      <td>571403</td>\n",
       "      <td>0.018775</td>\n",
       "      <td>16182.667785</td>\n",
       "      <td>2.731671e+06</td>\n",
       "      <td>-2213.759582</td>\n",
       "      <td>25890.101718</td>\n",
       "      <td>20300.126244</td>\n",
       "      <td>7610.979625</td>\n",
       "      <td>4857</td>\n",
       "      <td>1.672066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3144</th>\n",
       "      <td>2021-07-23</td>\n",
       "      <td>33498.822498</td>\n",
       "      <td>796273</td>\n",
       "      <td>364166</td>\n",
       "      <td>59.719880</td>\n",
       "      <td>23.529701</td>\n",
       "      <td>0.016745</td>\n",
       "      <td>2.097631e+08</td>\n",
       "      <td>1.118126e+09</td>\n",
       "      <td>0.424096</td>\n",
       "      <td>...</td>\n",
       "      <td>581919</td>\n",
       "      <td>0.016547</td>\n",
       "      <td>16133.447684</td>\n",
       "      <td>2.730266e+06</td>\n",
       "      <td>-3733.717472</td>\n",
       "      <td>24982.228255</td>\n",
       "      <td>26384.345094</td>\n",
       "      <td>7136.539245</td>\n",
       "      <td>4854</td>\n",
       "      <td>1.736907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>2021-07-24</td>\n",
       "      <td>34265.556245</td>\n",
       "      <td>719166</td>\n",
       "      <td>310767</td>\n",
       "      <td>84.115391</td>\n",
       "      <td>24.284639</td>\n",
       "      <td>0.011888</td>\n",
       "      <td>1.754172e+08</td>\n",
       "      <td>8.854552e+07</td>\n",
       "      <td>0.436826</td>\n",
       "      <td>...</td>\n",
       "      <td>497264</td>\n",
       "      <td>0.018897</td>\n",
       "      <td>16138.883870</td>\n",
       "      <td>2.733372e+06</td>\n",
       "      <td>-420.388112</td>\n",
       "      <td>21340.021595</td>\n",
       "      <td>18230.858067</td>\n",
       "      <td>7378.680342</td>\n",
       "      <td>4517</td>\n",
       "      <td>1.776167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3146</th>\n",
       "      <td>2021-07-25</td>\n",
       "      <td>35242.644357</td>\n",
       "      <td>648141</td>\n",
       "      <td>280495</td>\n",
       "      <td>82.500304</td>\n",
       "      <td>25.437056</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>2.140275e+08</td>\n",
       "      <td>1.838939e+08</td>\n",
       "      <td>0.452372</td>\n",
       "      <td>...</td>\n",
       "      <td>440900</td>\n",
       "      <td>0.018772</td>\n",
       "      <td>16140.922273</td>\n",
       "      <td>2.727603e+06</td>\n",
       "      <td>3507.818108</td>\n",
       "      <td>20000.653413</td>\n",
       "      <td>25767.698253</td>\n",
       "      <td>11450.494324</td>\n",
       "      <td>3820</td>\n",
       "      <td>1.826590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3147 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Datetime         Price  Active Addresses  New Addresses  NVT Ratio   \\\n",
       "0     2012-12-13     13.728511             45850          25807    2.800119   \n",
       "1     2012-12-14     13.604543             41453          23215    3.696235   \n",
       "2     2012-12-15     13.510539             34372          19291    6.595165   \n",
       "3     2012-12-16     13.395529             35514          19794    6.077174   \n",
       "4     2012-12-17     13.233350             40773          23932    6.177490   \n",
       "...          ...           ...               ...            ...         ...   \n",
       "3142  2021-07-21  32131.635487            811197         366924   41.338808   \n",
       "3143  2021-07-22  32328.209838            802115         364808   56.976622   \n",
       "3144  2021-07-23  33498.822498            796273         364166   59.719880   \n",
       "3145  2021-07-24  34265.556245            719166         310767   84.115391   \n",
       "3146  2021-07-25  35242.644357            648141         280495   82.500304   \n",
       "\n",
       "      NVT Signal  Velocity  Realized Profit   Realized Loss  \\\n",
       "0       3.747164  0.357128      3.362596e+05   4.352469e+04   \n",
       "1       3.758553  0.270546      1.746492e+05   4.126883e+04   \n",
       "2       3.895515  0.151626      6.065564e+04   2.847964e+04   \n",
       "3       4.022917  0.164550      9.175516e+04   3.742280e+04   \n",
       "4       4.147675  0.161878      6.737691e+04   9.005393e+04   \n",
       "...          ...       ...               ...            ...   \n",
       "3142   21.936868  0.024190      3.961132e+08   3.665613e+08   \n",
       "3143   22.512967  0.017551      3.715456e+08   1.744004e+08   \n",
       "3144   23.529701  0.016745      2.097631e+08   1.118126e+09   \n",
       "3145   24.284639  0.011888      1.754172e+08   8.854552e+07   \n",
       "3146   25.437056  0.012121      2.140275e+08   1.838939e+08   \n",
       "\n",
       "      Net_Unrealized_ProfitorLoss_(NUPL)  ...  Receiving Addresses  \\\n",
       "0                               0.464531  ...                34475   \n",
       "1                               0.456186  ...                31972   \n",
       "2                               0.454525  ...                27533   \n",
       "3                               0.447717  ...                28438   \n",
       "4                               0.443454  ...                33083   \n",
       "...                                  ...  ...                  ...   \n",
       "3142                            0.398450  ...               571527   \n",
       "3143                            0.401763  ...               571403   \n",
       "3144                            0.424096  ...               581919   \n",
       "3145                            0.436826  ...               497264   \n",
       "3146                            0.452372  ...               440900   \n",
       "\n",
       "      Inflation Rate   Balanced Price  Exchange Balance (Total)   \\\n",
       "0            0.119919        6.031378               1.210780e+03   \n",
       "1            0.095951        6.043843               2.533150e+03   \n",
       "2            0.105433        6.048364               2.992707e+03   \n",
       "3            0.100640        6.054062               3.060564e+03   \n",
       "4            0.122683        6.053462               1.238189e+03   \n",
       "...               ...             ...                        ...   \n",
       "3142         0.017785    16172.892878               2.726084e+06   \n",
       "3143         0.018775    16182.667785               2.731671e+06   \n",
       "3144         0.016547    16133.447684               2.730266e+06   \n",
       "3145         0.018897    16138.883870               2.733372e+06   \n",
       "3146         0.018772    16140.922273               2.727603e+06   \n",
       "\n",
       "      Exchange Net Position Change  Exchange Inflow Volume (Total)  \\\n",
       "0                      1006.364620                     3963.202238   \n",
       "1                      2177.125081                     5517.487995   \n",
       "2                      2107.685343                     1795.413172   \n",
       "3                      2836.683769                     2168.423522   \n",
       "4                       502.457143                     4337.639201   \n",
       "...                            ...                             ...   \n",
       "3142                  -8964.576554                    39774.144754   \n",
       "3143                  -2213.759582                    25890.101718   \n",
       "3144                  -3733.717472                    24982.228255   \n",
       "3145                   -420.388112                    21340.021595   \n",
       "3146                   3507.818108                    20000.653413   \n",
       "\n",
       "      Exchange Outflow Volume (Total)   Inter-Exchange Volume  \\\n",
       "0                          3646.982938               0.000051   \n",
       "1                          4195.092506               0.000000   \n",
       "2                          1335.838433               0.000000   \n",
       "3                          2100.548977               0.000000   \n",
       "4                          6159.981340               0.000000   \n",
       "...                                ...                    ...   \n",
       "3142                      42650.265681           12943.855953   \n",
       "3143                      20300.126244            7610.979625   \n",
       "3144                      26384.345094            7136.539245   \n",
       "3145                      18230.858067            7378.680342   \n",
       "3146                      25767.698253           11450.494324   \n",
       "\n",
       "      Inter-Exchange Transfers      MVRV  \n",
       "0                            1  1.867095  \n",
       "1                            0  1.846665  \n",
       "2                            0  1.832728  \n",
       "3                            0  1.815466  \n",
       "4                            0  1.793560  \n",
       "...                        ...       ...  \n",
       "3142                      5480  1.662858  \n",
       "3143                      4857  1.672066  \n",
       "3144                      4854  1.736907  \n",
       "3145                      4517  1.776167  \n",
       "3146                      3820  1.826590  \n",
       "\n",
       "[3147 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/Data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8aacedc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Active Addresses</th>\n",
       "      <th>New Addresses</th>\n",
       "      <th>NVT Ratio</th>\n",
       "      <th>NVT Signal</th>\n",
       "      <th>Velocity</th>\n",
       "      <th>Realized Profit</th>\n",
       "      <th>Realized Loss</th>\n",
       "      <th>Net_Unrealized_ProfitorLoss_(NUPL)</th>\n",
       "      <th>Relative_Unrealized_Profit</th>\n",
       "      <th>...</th>\n",
       "      <th>Inflation Rate</th>\n",
       "      <th>Balanced Price</th>\n",
       "      <th>Exchange Balance (Total)</th>\n",
       "      <th>Exchange Net Position Change</th>\n",
       "      <th>Exchange Inflow Volume (Total)</th>\n",
       "      <th>Exchange Outflow Volume (Total)</th>\n",
       "      <th>Inter-Exchange Volume</th>\n",
       "      <th>Inter-Exchange Transfers</th>\n",
       "      <th>MVRV</th>\n",
       "      <th>Returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-12-14</th>\n",
       "      <td>13.604543</td>\n",
       "      <td>41453</td>\n",
       "      <td>23215</td>\n",
       "      <td>3.696235</td>\n",
       "      <td>3.758553</td>\n",
       "      <td>0.270546</td>\n",
       "      <td>1.746492e+05</td>\n",
       "      <td>4.126883e+04</td>\n",
       "      <td>0.456186</td>\n",
       "      <td>0.477545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095951</td>\n",
       "      <td>6.043843</td>\n",
       "      <td>2.533150e+03</td>\n",
       "      <td>2177.125081</td>\n",
       "      <td>5517.487995</td>\n",
       "      <td>4195.092506</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.846665</td>\n",
       "      <td>-0.009071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-15</th>\n",
       "      <td>13.510539</td>\n",
       "      <td>34372</td>\n",
       "      <td>19291</td>\n",
       "      <td>6.595165</td>\n",
       "      <td>3.895515</td>\n",
       "      <td>0.151626</td>\n",
       "      <td>6.065564e+04</td>\n",
       "      <td>2.847964e+04</td>\n",
       "      <td>0.454525</td>\n",
       "      <td>0.476109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105433</td>\n",
       "      <td>6.048364</td>\n",
       "      <td>2.992707e+03</td>\n",
       "      <td>2107.685343</td>\n",
       "      <td>1795.413172</td>\n",
       "      <td>1335.838433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.832728</td>\n",
       "      <td>-0.006934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-16</th>\n",
       "      <td>13.395529</td>\n",
       "      <td>35514</td>\n",
       "      <td>19794</td>\n",
       "      <td>6.077174</td>\n",
       "      <td>4.022917</td>\n",
       "      <td>0.164550</td>\n",
       "      <td>9.175516e+04</td>\n",
       "      <td>3.742280e+04</td>\n",
       "      <td>0.447717</td>\n",
       "      <td>0.471153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100640</td>\n",
       "      <td>6.054062</td>\n",
       "      <td>3.060564e+03</td>\n",
       "      <td>2836.683769</td>\n",
       "      <td>2168.423522</td>\n",
       "      <td>2100.548977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.815466</td>\n",
       "      <td>-0.008549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-17</th>\n",
       "      <td>13.233350</td>\n",
       "      <td>40773</td>\n",
       "      <td>23932</td>\n",
       "      <td>6.177490</td>\n",
       "      <td>4.147675</td>\n",
       "      <td>0.161878</td>\n",
       "      <td>6.737691e+04</td>\n",
       "      <td>9.005393e+04</td>\n",
       "      <td>0.443454</td>\n",
       "      <td>0.468049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122683</td>\n",
       "      <td>6.053462</td>\n",
       "      <td>1.238189e+03</td>\n",
       "      <td>502.457143</td>\n",
       "      <td>4337.639201</td>\n",
       "      <td>6159.981340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.793560</td>\n",
       "      <td>-0.012181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-18</th>\n",
       "      <td>13.250366</td>\n",
       "      <td>47848</td>\n",
       "      <td>29116</td>\n",
       "      <td>4.621291</td>\n",
       "      <td>4.705011</td>\n",
       "      <td>0.216390</td>\n",
       "      <td>1.277631e+05</td>\n",
       "      <td>6.177744e+04</td>\n",
       "      <td>0.443170</td>\n",
       "      <td>0.467409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113957</td>\n",
       "      <td>6.059767</td>\n",
       "      <td>2.359469e+03</td>\n",
       "      <td>1417.242297</td>\n",
       "      <td>5516.255662</td>\n",
       "      <td>4394.943516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.793914</td>\n",
       "      <td>0.001285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-21</th>\n",
       "      <td>32131.635487</td>\n",
       "      <td>811197</td>\n",
       "      <td>366924</td>\n",
       "      <td>41.338808</td>\n",
       "      <td>21.936868</td>\n",
       "      <td>0.024190</td>\n",
       "      <td>3.961132e+08</td>\n",
       "      <td>3.665613e+08</td>\n",
       "      <td>0.398450</td>\n",
       "      <td>0.524104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017785</td>\n",
       "      <td>16172.892878</td>\n",
       "      <td>2.726084e+06</td>\n",
       "      <td>-8964.576554</td>\n",
       "      <td>39774.144754</td>\n",
       "      <td>42650.265681</td>\n",
       "      <td>12943.855953</td>\n",
       "      <td>5480</td>\n",
       "      <td>1.662858</td>\n",
       "      <td>0.075903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-22</th>\n",
       "      <td>32328.209838</td>\n",
       "      <td>802115</td>\n",
       "      <td>364808</td>\n",
       "      <td>56.976622</td>\n",
       "      <td>22.512967</td>\n",
       "      <td>0.017551</td>\n",
       "      <td>3.715456e+08</td>\n",
       "      <td>1.744004e+08</td>\n",
       "      <td>0.401763</td>\n",
       "      <td>0.524639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018775</td>\n",
       "      <td>16182.667785</td>\n",
       "      <td>2.731671e+06</td>\n",
       "      <td>-2213.759582</td>\n",
       "      <td>25890.101718</td>\n",
       "      <td>20300.126244</td>\n",
       "      <td>7610.979625</td>\n",
       "      <td>4857</td>\n",
       "      <td>1.672066</td>\n",
       "      <td>0.006099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-23</th>\n",
       "      <td>33498.822498</td>\n",
       "      <td>796273</td>\n",
       "      <td>364166</td>\n",
       "      <td>59.719880</td>\n",
       "      <td>23.529701</td>\n",
       "      <td>0.016745</td>\n",
       "      <td>2.097631e+08</td>\n",
       "      <td>1.118126e+09</td>\n",
       "      <td>0.424096</td>\n",
       "      <td>0.531201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016547</td>\n",
       "      <td>16133.447684</td>\n",
       "      <td>2.730266e+06</td>\n",
       "      <td>-3733.717472</td>\n",
       "      <td>24982.228255</td>\n",
       "      <td>26384.345094</td>\n",
       "      <td>7136.539245</td>\n",
       "      <td>4854</td>\n",
       "      <td>1.736907</td>\n",
       "      <td>0.035570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-24</th>\n",
       "      <td>34265.556245</td>\n",
       "      <td>719166</td>\n",
       "      <td>310767</td>\n",
       "      <td>84.115391</td>\n",
       "      <td>24.284639</td>\n",
       "      <td>0.011888</td>\n",
       "      <td>1.754172e+08</td>\n",
       "      <td>8.854552e+07</td>\n",
       "      <td>0.436826</td>\n",
       "      <td>0.535715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018897</td>\n",
       "      <td>16138.883870</td>\n",
       "      <td>2.733372e+06</td>\n",
       "      <td>-420.388112</td>\n",
       "      <td>21340.021595</td>\n",
       "      <td>18230.858067</td>\n",
       "      <td>7378.680342</td>\n",
       "      <td>4517</td>\n",
       "      <td>1.776167</td>\n",
       "      <td>0.022630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-25</th>\n",
       "      <td>35242.644357</td>\n",
       "      <td>648141</td>\n",
       "      <td>280495</td>\n",
       "      <td>82.500304</td>\n",
       "      <td>25.437056</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>2.140275e+08</td>\n",
       "      <td>1.838939e+08</td>\n",
       "      <td>0.452372</td>\n",
       "      <td>0.541714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018772</td>\n",
       "      <td>16140.922273</td>\n",
       "      <td>2.727603e+06</td>\n",
       "      <td>3507.818108</td>\n",
       "      <td>20000.653413</td>\n",
       "      <td>25767.698253</td>\n",
       "      <td>11450.494324</td>\n",
       "      <td>3820</td>\n",
       "      <td>1.826590</td>\n",
       "      <td>0.028116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3146 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Price  Active Addresses  New Addresses  NVT Ratio   \\\n",
       "Datetime                                                                \n",
       "2012-12-14     13.604543             41453          23215    3.696235   \n",
       "2012-12-15     13.510539             34372          19291    6.595165   \n",
       "2012-12-16     13.395529             35514          19794    6.077174   \n",
       "2012-12-17     13.233350             40773          23932    6.177490   \n",
       "2012-12-18     13.250366             47848          29116    4.621291   \n",
       "...                  ...               ...            ...         ...   \n",
       "2021-07-21  32131.635487            811197         366924   41.338808   \n",
       "2021-07-22  32328.209838            802115         364808   56.976622   \n",
       "2021-07-23  33498.822498            796273         364166   59.719880   \n",
       "2021-07-24  34265.556245            719166         310767   84.115391   \n",
       "2021-07-25  35242.644357            648141         280495   82.500304   \n",
       "\n",
       "            NVT Signal  Velocity  Realized Profit   Realized Loss  \\\n",
       "Datetime                                                            \n",
       "2012-12-14    3.758553  0.270546      1.746492e+05   4.126883e+04   \n",
       "2012-12-15    3.895515  0.151626      6.065564e+04   2.847964e+04   \n",
       "2012-12-16    4.022917  0.164550      9.175516e+04   3.742280e+04   \n",
       "2012-12-17    4.147675  0.161878      6.737691e+04   9.005393e+04   \n",
       "2012-12-18    4.705011  0.216390      1.277631e+05   6.177744e+04   \n",
       "...                ...       ...               ...            ...   \n",
       "2021-07-21   21.936868  0.024190      3.961132e+08   3.665613e+08   \n",
       "2021-07-22   22.512967  0.017551      3.715456e+08   1.744004e+08   \n",
       "2021-07-23   23.529701  0.016745      2.097631e+08   1.118126e+09   \n",
       "2021-07-24   24.284639  0.011888      1.754172e+08   8.854552e+07   \n",
       "2021-07-25   25.437056  0.012121      2.140275e+08   1.838939e+08   \n",
       "\n",
       "            Net_Unrealized_ProfitorLoss_(NUPL)  Relative_Unrealized_Profit  \\\n",
       "Datetime                                                                     \n",
       "2012-12-14                            0.456186                    0.477545   \n",
       "2012-12-15                            0.454525                    0.476109   \n",
       "2012-12-16                            0.447717                    0.471153   \n",
       "2012-12-17                            0.443454                    0.468049   \n",
       "2012-12-18                            0.443170                    0.467409   \n",
       "...                                        ...                         ...   \n",
       "2021-07-21                            0.398450                    0.524104   \n",
       "2021-07-22                            0.401763                    0.524639   \n",
       "2021-07-23                            0.424096                    0.531201   \n",
       "2021-07-24                            0.436826                    0.535715   \n",
       "2021-07-25                            0.452372                    0.541714   \n",
       "\n",
       "            ...  Inflation Rate   Balanced Price  Exchange Balance (Total)   \\\n",
       "Datetime    ...                                                               \n",
       "2012-12-14  ...         0.095951        6.043843               2.533150e+03   \n",
       "2012-12-15  ...         0.105433        6.048364               2.992707e+03   \n",
       "2012-12-16  ...         0.100640        6.054062               3.060564e+03   \n",
       "2012-12-17  ...         0.122683        6.053462               1.238189e+03   \n",
       "2012-12-18  ...         0.113957        6.059767               2.359469e+03   \n",
       "...         ...              ...             ...                        ...   \n",
       "2021-07-21  ...         0.017785    16172.892878               2.726084e+06   \n",
       "2021-07-22  ...         0.018775    16182.667785               2.731671e+06   \n",
       "2021-07-23  ...         0.016547    16133.447684               2.730266e+06   \n",
       "2021-07-24  ...         0.018897    16138.883870               2.733372e+06   \n",
       "2021-07-25  ...         0.018772    16140.922273               2.727603e+06   \n",
       "\n",
       "            Exchange Net Position Change  Exchange Inflow Volume (Total)  \\\n",
       "Datetime                                                                   \n",
       "2012-12-14                   2177.125081                     5517.487995   \n",
       "2012-12-15                   2107.685343                     1795.413172   \n",
       "2012-12-16                   2836.683769                     2168.423522   \n",
       "2012-12-17                    502.457143                     4337.639201   \n",
       "2012-12-18                   1417.242297                     5516.255662   \n",
       "...                                  ...                             ...   \n",
       "2021-07-21                  -8964.576554                    39774.144754   \n",
       "2021-07-22                  -2213.759582                    25890.101718   \n",
       "2021-07-23                  -3733.717472                    24982.228255   \n",
       "2021-07-24                   -420.388112                    21340.021595   \n",
       "2021-07-25                   3507.818108                    20000.653413   \n",
       "\n",
       "            Exchange Outflow Volume (Total)   Inter-Exchange Volume  \\\n",
       "Datetime                                                              \n",
       "2012-12-14                       4195.092506               0.000000   \n",
       "2012-12-15                       1335.838433               0.000000   \n",
       "2012-12-16                       2100.548977               0.000000   \n",
       "2012-12-17                       6159.981340               0.000000   \n",
       "2012-12-18                       4394.943516               0.000000   \n",
       "...                                      ...                    ...   \n",
       "2021-07-21                      42650.265681           12943.855953   \n",
       "2021-07-22                      20300.126244            7610.979625   \n",
       "2021-07-23                      26384.345094            7136.539245   \n",
       "2021-07-24                      18230.858067            7378.680342   \n",
       "2021-07-25                      25767.698253           11450.494324   \n",
       "\n",
       "            Inter-Exchange Transfers      MVRV   Returns  \n",
       "Datetime                                                  \n",
       "2012-12-14                         0  1.846665 -0.009071  \n",
       "2012-12-15                         0  1.832728 -0.006934  \n",
       "2012-12-16                         0  1.815466 -0.008549  \n",
       "2012-12-17                         0  1.793560 -0.012181  \n",
       "2012-12-18                         0  1.793914  0.001285  \n",
       "...                              ...       ...       ...  \n",
       "2021-07-21                      5480  1.662858  0.075903  \n",
       "2021-07-22                      4857  1.672066  0.006099  \n",
       "2021-07-23                      4854  1.736907  0.035570  \n",
       "2021-07-24                      4517  1.776167  0.022630  \n",
       "2021-07-25                      3820  1.826590  0.028116  \n",
       "\n",
       "[3146 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Returns'] = np.log(df['Price'] / df['Price'].shift(1))\n",
    "df.dropna(inplace = True)\n",
    "df=df.set_index('Datetime',inplace = False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fdcfca",
   "metadata": {},
   "source": [
    "# Add Lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f0a464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of days lagged data to use for each sample\n",
    "lags = 5\n",
    "\n",
    "# Empty list to store feature column names\n",
    "cols = [] \n",
    "\n",
    "features = list(df.keys())       \n",
    "\n",
    "# For each feature\n",
    "for f in features:\n",
    "    for lag in range(1, lags + 1):\n",
    "        col = f'{f}_lag_{lag}'\n",
    "        df[col] = df[f].shift(lag)\n",
    "        cols.append(col)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1399649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "X = df.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc690eba",
   "metadata": {},
   "source": [
    "# Defining the Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5640d27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3136</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3137</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3140</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3141 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0     1\n",
       "1     1\n",
       "2    -1\n",
       "3     1\n",
       "4    -1\n",
       "...  ..\n",
       "3136  1\n",
       "3137  1\n",
       "3138  1\n",
       "3139  1\n",
       "3140  1\n",
       "\n",
       "[3141 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our response feature will be the sign of BTC's returns (i.e. daily directional movement)\n",
    "Y = pd.DataFrame(list(np.where(df['Returns'] >= 0, 1, -1))) \n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc621d6a",
   "metadata": {},
   "source": [
    "# Transforming the features X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3aec6c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Active Addresses</th>\n",
       "      <th>New Addresses</th>\n",
       "      <th>NVT Ratio</th>\n",
       "      <th>NVT Signal</th>\n",
       "      <th>Velocity</th>\n",
       "      <th>Realized Profit</th>\n",
       "      <th>Realized Loss</th>\n",
       "      <th>Net_Unrealized_ProfitorLoss_(NUPL)</th>\n",
       "      <th>Relative_Unrealized_Profit</th>\n",
       "      <th>...</th>\n",
       "      <th>MVRV_lag_1</th>\n",
       "      <th>MVRV_lag_2</th>\n",
       "      <th>MVRV_lag_3</th>\n",
       "      <th>MVRV_lag_4</th>\n",
       "      <th>MVRV_lag_5</th>\n",
       "      <th>Returns_lag_1</th>\n",
       "      <th>Returns_lag_2</th>\n",
       "      <th>Returns_lag_3</th>\n",
       "      <th>Returns_lag_4</th>\n",
       "      <th>Returns_lag_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-12-19</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.010088</td>\n",
       "      <td>0.010206</td>\n",
       "      <td>0.113200</td>\n",
       "      <td>0.033391</td>\n",
       "      <td>0.019808</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.766035</td>\n",
       "      <td>0.321242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220225</td>\n",
       "      <td>0.220162</td>\n",
       "      <td>0.224052</td>\n",
       "      <td>0.227118</td>\n",
       "      <td>0.229593</td>\n",
       "      <td>0.667610</td>\n",
       "      <td>0.654390</td>\n",
       "      <td>0.657955</td>\n",
       "      <td>0.659541</td>\n",
       "      <td>0.657443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-20</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.006919</td>\n",
       "      <td>0.006074</td>\n",
       "      <td>0.140034</td>\n",
       "      <td>0.044642</td>\n",
       "      <td>0.015595</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.768545</td>\n",
       "      <td>0.326701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226432</td>\n",
       "      <td>0.220225</td>\n",
       "      <td>0.220162</td>\n",
       "      <td>0.224052</td>\n",
       "      <td>0.227118</td>\n",
       "      <td>0.686874</td>\n",
       "      <td>0.667610</td>\n",
       "      <td>0.654390</td>\n",
       "      <td>0.657955</td>\n",
       "      <td>0.659541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-21</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.012038</td>\n",
       "      <td>0.012327</td>\n",
       "      <td>0.073602</td>\n",
       "      <td>0.050067</td>\n",
       "      <td>0.031448</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.765958</td>\n",
       "      <td>0.320034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226342</td>\n",
       "      <td>0.226432</td>\n",
       "      <td>0.220225</td>\n",
       "      <td>0.220162</td>\n",
       "      <td>0.224052</td>\n",
       "      <td>0.668155</td>\n",
       "      <td>0.686874</td>\n",
       "      <td>0.667610</td>\n",
       "      <td>0.654390</td>\n",
       "      <td>0.657955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-22</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.018746</td>\n",
       "      <td>0.024273</td>\n",
       "      <td>0.090406</td>\n",
       "      <td>0.054372</td>\n",
       "      <td>0.025298</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.763955</td>\n",
       "      <td>0.315282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220237</td>\n",
       "      <td>0.226342</td>\n",
       "      <td>0.226432</td>\n",
       "      <td>0.220225</td>\n",
       "      <td>0.220162</td>\n",
       "      <td>0.649456</td>\n",
       "      <td>0.668155</td>\n",
       "      <td>0.686874</td>\n",
       "      <td>0.667610</td>\n",
       "      <td>0.654390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-23</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>0.005356</td>\n",
       "      <td>0.145858</td>\n",
       "      <td>0.058481</td>\n",
       "      <td>0.014881</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.761012</td>\n",
       "      <td>0.308656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222001</td>\n",
       "      <td>0.220237</td>\n",
       "      <td>0.226342</td>\n",
       "      <td>0.226432</td>\n",
       "      <td>0.220225</td>\n",
       "      <td>0.672114</td>\n",
       "      <td>0.649456</td>\n",
       "      <td>0.668155</td>\n",
       "      <td>0.686874</td>\n",
       "      <td>0.667610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-21</th>\n",
       "      <td>0.505084</td>\n",
       "      <td>0.586131</td>\n",
       "      <td>0.447150</td>\n",
       "      <td>0.472836</td>\n",
       "      <td>0.290607</td>\n",
       "      <td>0.002868</td>\n",
       "      <td>0.069331</td>\n",
       "      <td>0.080836</td>\n",
       "      <td>0.735047</td>\n",
       "      <td>0.417663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175394</td>\n",
       "      <td>0.184897</td>\n",
       "      <td>0.193745</td>\n",
       "      <td>0.191184</td>\n",
       "      <td>0.191203</td>\n",
       "      <td>0.632289</td>\n",
       "      <td>0.635632</td>\n",
       "      <td>0.674573</td>\n",
       "      <td>0.670153</td>\n",
       "      <td>0.658738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-22</th>\n",
       "      <td>0.508175</td>\n",
       "      <td>0.579317</td>\n",
       "      <td>0.444450</td>\n",
       "      <td>0.652681</td>\n",
       "      <td>0.299440</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.065031</td>\n",
       "      <td>0.038459</td>\n",
       "      <td>0.737039</td>\n",
       "      <td>0.418652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196950</td>\n",
       "      <td>0.175394</td>\n",
       "      <td>0.184897</td>\n",
       "      <td>0.193745</td>\n",
       "      <td>0.191184</td>\n",
       "      <td>0.740866</td>\n",
       "      <td>0.632289</td>\n",
       "      <td>0.635632</td>\n",
       "      <td>0.674573</td>\n",
       "      <td>0.670153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-23</th>\n",
       "      <td>0.526583</td>\n",
       "      <td>0.574933</td>\n",
       "      <td>0.443630</td>\n",
       "      <td>0.684231</td>\n",
       "      <td>0.315028</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>0.036713</td>\n",
       "      <td>0.246581</td>\n",
       "      <td>0.750471</td>\n",
       "      <td>0.430787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198585</td>\n",
       "      <td>0.196950</td>\n",
       "      <td>0.175394</td>\n",
       "      <td>0.184897</td>\n",
       "      <td>0.193745</td>\n",
       "      <td>0.672336</td>\n",
       "      <td>0.740866</td>\n",
       "      <td>0.632289</td>\n",
       "      <td>0.635632</td>\n",
       "      <td>0.674573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-24</th>\n",
       "      <td>0.538641</td>\n",
       "      <td>0.517077</td>\n",
       "      <td>0.375491</td>\n",
       "      <td>0.964795</td>\n",
       "      <td>0.326603</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.030701</td>\n",
       "      <td>0.019525</td>\n",
       "      <td>0.758127</td>\n",
       "      <td>0.439135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210101</td>\n",
       "      <td>0.198585</td>\n",
       "      <td>0.196950</td>\n",
       "      <td>0.175394</td>\n",
       "      <td>0.184897</td>\n",
       "      <td>0.701269</td>\n",
       "      <td>0.672336</td>\n",
       "      <td>0.740866</td>\n",
       "      <td>0.632289</td>\n",
       "      <td>0.635632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-25</th>\n",
       "      <td>0.554006</td>\n",
       "      <td>0.463784</td>\n",
       "      <td>0.336863</td>\n",
       "      <td>0.946220</td>\n",
       "      <td>0.344272</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.037459</td>\n",
       "      <td>0.040552</td>\n",
       "      <td>0.767476</td>\n",
       "      <td>0.450228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217073</td>\n",
       "      <td>0.210101</td>\n",
       "      <td>0.198585</td>\n",
       "      <td>0.196950</td>\n",
       "      <td>0.175394</td>\n",
       "      <td>0.688566</td>\n",
       "      <td>0.701269</td>\n",
       "      <td>0.672336</td>\n",
       "      <td>0.740866</td>\n",
       "      <td>0.632289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3141 rows × 144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Price  Active Addresses  New Addresses  NVT Ratio   NVT Signal  \\\n",
       "Datetime                                                                        \n",
       "2012-12-19  0.000008          0.010088       0.010206    0.113200    0.033391   \n",
       "2012-12-20  0.000008          0.006919       0.006074    0.140034    0.044642   \n",
       "2012-12-21  0.000005          0.012038       0.012327    0.073602    0.050067   \n",
       "2012-12-22  0.000006          0.018746       0.024273    0.090406    0.054372   \n",
       "2012-12-23  0.000005          0.007230       0.005356    0.145858    0.058481   \n",
       "...              ...               ...            ...         ...         ...   \n",
       "2021-07-21  0.505084          0.586131       0.447150    0.472836    0.290607   \n",
       "2021-07-22  0.508175          0.579317       0.444450    0.652681    0.299440   \n",
       "2021-07-23  0.526583          0.574933       0.443630    0.684231    0.315028   \n",
       "2021-07-24  0.538641          0.517077       0.375491    0.964795    0.326603   \n",
       "2021-07-25  0.554006          0.463784       0.336863    0.946220    0.344272   \n",
       "\n",
       "            Velocity  Realized Profit   Realized Loss  \\\n",
       "Datetime                                                \n",
       "2012-12-19  0.019808          0.000021       0.000006   \n",
       "2012-12-20  0.015595          0.000028       0.000005   \n",
       "2012-12-21  0.031448          0.000024       0.000006   \n",
       "2012-12-22  0.025298          0.000006       0.000009   \n",
       "2012-12-23  0.014881          0.000003       0.000007   \n",
       "...              ...               ...            ...   \n",
       "2021-07-21  0.002868          0.069331       0.080836   \n",
       "2021-07-22  0.001371          0.065031       0.038459   \n",
       "2021-07-23  0.001189          0.036713       0.246581   \n",
       "2021-07-24  0.000094          0.030701       0.019525   \n",
       "2021-07-25  0.000147          0.037459       0.040552   \n",
       "\n",
       "            Net_Unrealized_ProfitorLoss_(NUPL)  Relative_Unrealized_Profit  \\\n",
       "Datetime                                                                     \n",
       "2012-12-19                            0.766035                    0.321242   \n",
       "2012-12-20                            0.768545                    0.326701   \n",
       "2012-12-21                            0.765958                    0.320034   \n",
       "2012-12-22                            0.763955                    0.315282   \n",
       "2012-12-23                            0.761012                    0.308656   \n",
       "...                                        ...                         ...   \n",
       "2021-07-21                            0.735047                    0.417663   \n",
       "2021-07-22                            0.737039                    0.418652   \n",
       "2021-07-23                            0.750471                    0.430787   \n",
       "2021-07-24                            0.758127                    0.439135   \n",
       "2021-07-25                            0.767476                    0.450228   \n",
       "\n",
       "            ...  MVRV_lag_1  MVRV_lag_2  MVRV_lag_3  MVRV_lag_4  MVRV_lag_5  \\\n",
       "Datetime    ...                                                               \n",
       "2012-12-19  ...    0.220225    0.220162    0.224052    0.227118    0.229593   \n",
       "2012-12-20  ...    0.226432    0.220225    0.220162    0.224052    0.227118   \n",
       "2012-12-21  ...    0.226342    0.226432    0.220225    0.220162    0.224052   \n",
       "2012-12-22  ...    0.220237    0.226342    0.226432    0.220225    0.220162   \n",
       "2012-12-23  ...    0.222001    0.220237    0.226342    0.226432    0.220225   \n",
       "...         ...         ...         ...         ...         ...         ...   \n",
       "2021-07-21  ...    0.175394    0.184897    0.193745    0.191184    0.191203   \n",
       "2021-07-22  ...    0.196950    0.175394    0.184897    0.193745    0.191184   \n",
       "2021-07-23  ...    0.198585    0.196950    0.175394    0.184897    0.193745   \n",
       "2021-07-24  ...    0.210101    0.198585    0.196950    0.175394    0.184897   \n",
       "2021-07-25  ...    0.217073    0.210101    0.198585    0.196950    0.175394   \n",
       "\n",
       "            Returns_lag_1  Returns_lag_2  Returns_lag_3  Returns_lag_4  \\\n",
       "Datetime                                                                 \n",
       "2012-12-19       0.667610       0.654390       0.657955       0.659541   \n",
       "2012-12-20       0.686874       0.667610       0.654390       0.657955   \n",
       "2012-12-21       0.668155       0.686874       0.667610       0.654390   \n",
       "2012-12-22       0.649456       0.668155       0.686874       0.667610   \n",
       "2012-12-23       0.672114       0.649456       0.668155       0.686874   \n",
       "...                   ...            ...            ...            ...   \n",
       "2021-07-21       0.632289       0.635632       0.674573       0.670153   \n",
       "2021-07-22       0.740866       0.632289       0.635632       0.674573   \n",
       "2021-07-23       0.672336       0.740866       0.632289       0.635632   \n",
       "2021-07-24       0.701269       0.672336       0.740866       0.632289   \n",
       "2021-07-25       0.688566       0.701269       0.672336       0.740866   \n",
       "\n",
       "            Returns_lag_5  \n",
       "Datetime                   \n",
       "2012-12-19       0.657443  \n",
       "2012-12-20       0.659541  \n",
       "2012-12-21       0.657955  \n",
       "2012-12-22       0.654390  \n",
       "2012-12-23       0.667610  \n",
       "...                   ...  \n",
       "2021-07-21       0.658738  \n",
       "2021-07-22       0.670153  \n",
       "2021-07-23       0.674573  \n",
       "2021-07-24       0.635632  \n",
       "2021-07-25       0.632289  \n",
       "\n",
       "[3141 rows x 144 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We scale the data \n",
    "scaler = MinMaxScaler()\n",
    "scaled_X = scaler.fit_transform(X)\n",
    "\n",
    "# We let X as a dataframe\n",
    "X = pd.DataFrame(scaled_X,columns = list(df.keys()),\n",
    "                 index = df.index)  \n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25602775",
   "metadata": {},
   "source": [
    "# Encoding Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df792ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column_A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3136</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3137</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3140</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3141 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Column_A\n",
       "0            1\n",
       "1            1\n",
       "2            0\n",
       "3            1\n",
       "4            0\n",
       "...        ...\n",
       "3136         1\n",
       "3137         1\n",
       "3138         1\n",
       "3139         1\n",
       "3140         1\n",
       "\n",
       "[3141 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We transform Y to a binary classification problem's values (0 y 1)\n",
    "encoder = LabelEncoder() \n",
    "encoder.fit(Y) \n",
    "encoded_Y = encoder.transform(Y) \n",
    "# We transform encoded_Y into a dataframe in order to use .iloc and being able to make the \n",
    "# train/test split\n",
    "Y = pd.DataFrame(encoded_Y, columns = ['Column_A'], index = Y.index) \n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6c8622",
   "metadata": {},
   "source": [
    "# Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de5bc435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train data set\n",
    "# We have to twist the dataset\n",
    "\n",
    "split = int(len(X) * 0.7)\n",
    "\n",
    "X_train, y_train = X[:split], Y[:split]\n",
    "# Test data after train split\n",
    "X_test, y_test = X[split+3:], Y[split+3:]\n",
    "\n",
    "# Scale the features MinMax for training and test datasets\n",
    "scaler = MinMaxScaler()\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)\n",
    "\n",
    "# We change from array to dataframe\n",
    "X_train = pd.DataFrame(scaled_X_train,columns = X.columns,index = X.iloc[:split].index)\n",
    "y_train = pd.DataFrame(y_train,columns = Y.columns,index = Y[:split].index)\n",
    "X_test = pd.DataFrame(scaled_X_test,columns = X.columns,index = X[split+3:].index)\n",
    "y_test = pd.DataFrame(y_test,columns = Y.columns,index = Y[split+3:].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae27363",
   "metadata": {},
   "source": [
    "# Gaussian NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eea8130e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6918434243769334 (+/- 0.04719102760365728\n",
      "\n",
      "R2: -0.9553472566765091 (+/- 0.2555835655097976\n",
      "\n",
      "Accuracy for each folder: [0.54918033 0.48087432 0.42076503 0.6147541  0.53005464]\n",
      "\n",
      "Mean Accuracy 0.5191256830601093\n",
      "\n",
      "roc_auc 0.56905466782537\n",
      "\n",
      "max_error -1.0\n",
      "\n",
      "F1Score For Each Folder [0.26666667 0.         0.         0.76142132 0.21818182]\n",
      "\n",
      "F1Score Mean 0.24925396092908786\n",
      "\n",
      " clasification report for Classification Gaussian NB:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      1.00      0.64       444\n",
      "           1       0.00      0.00      0.00       496\n",
      "\n",
      "    accuracy                           0.47       940\n",
      "   macro avg       0.24      0.50      0.32       940\n",
      "weighted avg       0.22      0.47      0.30       940\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score, accuracy_score,recall_score, precision_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "model = GaussianNB(var_smoothing=0.1873817422860384)\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "\n",
    "# Performance \n",
    "rmse_GNB = np.sqrt(-cross_val_score(model, X_train, y_train, cv=tscv, scoring='neg_mean_squared_error'))\n",
    "R2_GNB = cross_val_score(model, X_train, y_train, cv=tscv, scoring='r2')\n",
    "roc_auc_GNB = cross_val_score(model, X_train, y_train, cv=tscv, scoring='roc_auc')\n",
    "Accuracy_GNB = cross_val_score(model, X_train, y_train, cv=tscv)\n",
    "max_error_GNB = cross_val_score(model, X_train, y_train, cv=tscv, scoring='max_error')\n",
    "f1Score_GNB=cross_val_score(model, X_train, y_train, cv=tscv, scoring='f1')\n",
    "\n",
    "\n",
    "print(f\"RMSE: {rmse_GNB.mean()} (+/- {rmse_GNB.std()}\")\n",
    "print(f\"\\nR2: {R2_GNB.mean()} (+/- {R2_GNB.std()}\")\n",
    "print(f\"\\nAccuracy for each folder: {Accuracy_GNB}\")\n",
    "print(f\"\\nMean Accuracy {Accuracy_GNB.mean()}\")\n",
    "print(f\"\\nroc_auc {roc_auc_GNB.mean()}\")\n",
    "print(f\"\\nmax_error {max_error_GNB.mean()}\")\n",
    "print(f\"\\nF1Score For Each Folder {f1Score_GNB}\")\n",
    "print(f\"\\nF1Score Mean {f1Score_GNB.mean()}\")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_predGNB=model.predict(X_test)\n",
    "print ('\\n clasification report for Classification Gaussian NB:\\n', classification_report(y_test,y_predGNB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d695f3bb",
   "metadata": {},
   "source": [
    "# GridSearch Gaussian NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d37946b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['priors', 'var_smoothing'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ea4ae06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV 1/5] END var_smoothing=1.0;, score=(train=0.505, test=0.538) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1.0;, score=(train=0.593, test=0.481) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1.0;, score=(train=0.550, test=0.421) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1.0;, score=(train=0.515, test=0.612) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1.0;, score=(train=0.524, test=0.503) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.8111308307896871;, score=(train=0.508, test=0.536) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.8111308307896871;, score=(train=0.594, test=0.481) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.8111308307896871;, score=(train=0.549, test=0.421) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.8111308307896871;, score=(train=0.521, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.8111308307896871;, score=(train=0.531, test=0.495) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.657933224657568;, score=(train=0.508, test=0.544) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.657933224657568;, score=(train=0.593, test=0.481) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.657933224657568;, score=(train=0.549, test=0.421) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.657933224657568;, score=(train=0.527, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.657933224657568;, score=(train=0.536, test=0.503) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.533669923120631;, score=(train=0.508, test=0.546) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.533669923120631;, score=(train=0.597, test=0.481) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.533669923120631;, score=(train=0.549, test=0.421) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.533669923120631;, score=(train=0.532, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.533669923120631;, score=(train=0.539, test=0.522) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.43287612810830584;, score=(train=0.511, test=0.544) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.43287612810830584;, score=(train=0.598, test=0.481) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.43287612810830584;, score=(train=0.549, test=0.421) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.43287612810830584;, score=(train=0.534, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.43287612810830584;, score=(train=0.546, test=0.549) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.3511191734215131;, score=(train=0.511, test=0.549) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.3511191734215131;, score=(train=0.597, test=0.481) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.3511191734215131;, score=(train=0.550, test=0.421) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.3511191734215131;, score=(train=0.534, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.3511191734215131;, score=(train=0.555, test=0.533) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.2848035868435802;, score=(train=0.514, test=0.546) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.2848035868435802;, score=(train=0.598, test=0.481) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.2848035868435802;, score=(train=0.551, test=0.421) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.2848035868435802;, score=(train=0.544, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.2848035868435802;, score=(train=0.558, test=0.519) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.23101297000831597;, score=(train=0.514, test=0.549) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.23101297000831597;, score=(train=0.595, test=0.481) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.23101297000831597;, score=(train=0.552, test=0.421) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.23101297000831597;, score=(train=0.557, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.23101297000831597;, score=(train=0.564, test=0.525) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.1873817422860384;, score=(train=0.519, test=0.549) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.1873817422860384;, score=(train=0.595, test=0.481) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.1873817422860384;, score=(train=0.551, test=0.421) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.1873817422860384;, score=(train=0.553, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.1873817422860384;, score=(train=0.566, test=0.530) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.15199110829529336;, score=(train=0.522, test=0.555) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.15199110829529336;, score=(train=0.595, test=0.481) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.15199110829529336;, score=(train=0.551, test=0.421) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.15199110829529336;, score=(train=0.563, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.15199110829529336;, score=(train=0.570, test=0.516) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.12328467394420659;, score=(train=0.535, test=0.571) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.12328467394420659;, score=(train=0.598, test=0.481) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.12328467394420659;, score=(train=0.551, test=0.421) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.12328467394420659;, score=(train=0.569, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.12328467394420659;, score=(train=0.577, test=0.505) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.1;, score=(train=0.541, test=0.568) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.1;, score=(train=0.598, test=0.481) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.1;, score=(train=0.552, test=0.421) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.1;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.1;, score=(train=0.581, test=0.505) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.08111308307896872;, score=(train=0.546, test=0.568) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.08111308307896872;, score=(train=0.598, test=0.481) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.08111308307896872;, score=(train=0.552, test=0.437) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.08111308307896872;, score=(train=0.578, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.08111308307896872;, score=(train=0.581, test=0.500) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.0657933224657568;, score=(train=0.552, test=0.566) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.0657933224657568;, score=(train=0.598, test=0.478) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.0657933224657568;, score=(train=0.553, test=0.454) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.0657933224657568;, score=(train=0.577, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.0657933224657568;, score=(train=0.586, test=0.497) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.0533669923120631;, score=(train=0.571, test=0.557) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.0533669923120631;, score=(train=0.598, test=0.478) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.0533669923120631;, score=(train=0.553, test=0.456) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.0533669923120631;, score=(train=0.576, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.0533669923120631;, score=(train=0.592, test=0.495) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.04328761281083057;, score=(train=0.576, test=0.560) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.04328761281083057;, score=(train=0.598, test=0.478) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.04328761281083057;, score=(train=0.555, test=0.475) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.04328761281083057;, score=(train=0.579, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.04328761281083057;, score=(train=0.596, test=0.495) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.03511191734215131;, score=(train=0.587, test=0.574) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.03511191734215131;, score=(train=0.601, test=0.478) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.03511191734215131;, score=(train=0.555, test=0.500) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.03511191734215131;, score=(train=0.576, test=0.615) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END var_smoothing=0.03511191734215131;, score=(train=0.602, test=0.495) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.02848035868435802;, score=(train=0.595, test=0.574) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.02848035868435802;, score=(train=0.604, test=0.478) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.02848035868435802;, score=(train=0.555, test=0.497) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.02848035868435802;, score=(train=0.577, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.02848035868435802;, score=(train=0.603, test=0.495) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.02310129700083159;, score=(train=0.617, test=0.577) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.02310129700083159;, score=(train=0.602, test=0.478) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.02310129700083159;, score=(train=0.561, test=0.508) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.02310129700083159;, score=(train=0.576, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.02310129700083159;, score=(train=0.606, test=0.495) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.01873817422860384;, score=(train=0.628, test=0.563) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.01873817422860384;, score=(train=0.602, test=0.478) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.01873817422860384;, score=(train=0.561, test=0.511) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.01873817422860384;, score=(train=0.576, test=0.612) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.01873817422860384;, score=(train=0.607, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.01519911082952933;, score=(train=0.633, test=0.571) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.01519911082952933;, score=(train=0.602, test=0.478) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.01519911082952933;, score=(train=0.562, test=0.511) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.01519911082952933;, score=(train=0.578, test=0.617) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.01519911082952933;, score=(train=0.609, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.012328467394420659;, score=(train=0.639, test=0.574) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.012328467394420659;, score=(train=0.602, test=0.478) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.012328467394420659;, score=(train=0.563, test=0.511) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.012328467394420659;, score=(train=0.579, test=0.620) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.012328467394420659;, score=(train=0.610, test=0.495) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.01;, score=(train=0.641, test=0.568) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.01;, score=(train=0.605, test=0.478) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.01;, score=(train=0.563, test=0.522) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.01;, score=(train=0.582, test=0.623) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.01;, score=(train=0.610, test=0.495) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.008111308307896872;, score=(train=0.633, test=0.555) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.008111308307896872;, score=(train=0.606, test=0.478) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.008111308307896872;, score=(train=0.564, test=0.533) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.008111308307896872;, score=(train=0.583, test=0.617) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.008111308307896872;, score=(train=0.610, test=0.495) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.006579332246575682;, score=(train=0.633, test=0.560) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.006579332246575682;, score=(train=0.608, test=0.478) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.006579332246575682;, score=(train=0.563, test=0.544) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.006579332246575682;, score=(train=0.584, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.006579332246575682;, score=(train=0.609, test=0.495) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.005336699231206307;, score=(train=0.639, test=0.563) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.005336699231206307;, score=(train=0.609, test=0.478) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.005336699231206307;, score=(train=0.564, test=0.555) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.005336699231206307;, score=(train=0.583, test=0.617) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.005336699231206307;, score=(train=0.610, test=0.495) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.004328761281083057;, score=(train=0.641, test=0.563) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.004328761281083057;, score=(train=0.610, test=0.478) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.004328761281083057;, score=(train=0.565, test=0.552) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.004328761281083057;, score=(train=0.582, test=0.617) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.004328761281083057;, score=(train=0.610, test=0.489) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.003511191734215131;, score=(train=0.647, test=0.552) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.003511191734215131;, score=(train=0.612, test=0.478) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.003511191734215131;, score=(train=0.564, test=0.549) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.003511191734215131;, score=(train=0.585, test=0.620) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.003511191734215131;, score=(train=0.612, test=0.489) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.002848035868435802;, score=(train=0.652, test=0.555) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.002848035868435802;, score=(train=0.610, test=0.478) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.002848035868435802;, score=(train=0.565, test=0.549) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.002848035868435802;, score=(train=0.586, test=0.620) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.002848035868435802;, score=(train=0.611, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.0023101297000831605;, score=(train=0.671, test=0.549) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.0023101297000831605;, score=(train=0.613, test=0.478) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.0023101297000831605;, score=(train=0.567, test=0.557) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.0023101297000831605;, score=(train=0.584, test=0.623) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.0023101297000831605;, score=(train=0.612, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.001873817422860383;, score=(train=0.677, test=0.549) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.001873817422860383;, score=(train=0.614, test=0.478) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.001873817422860383;, score=(train=0.568, test=0.563) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.001873817422860383;, score=(train=0.584, test=0.620) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.001873817422860383;, score=(train=0.614, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.0015199110829529332;, score=(train=0.688, test=0.546) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.0015199110829529332;, score=(train=0.617, test=0.478) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.0015199110829529332;, score=(train=0.568, test=0.566) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.0015199110829529332;, score=(train=0.584, test=0.617) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.0015199110829529332;, score=(train=0.615, test=0.495) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.0012328467394420659;, score=(train=0.682, test=0.546) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.0012328467394420659;, score=(train=0.617, test=0.478) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.0012328467394420659;, score=(train=0.566, test=0.574) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.0012328467394420659;, score=(train=0.585, test=0.617) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.0012328467394420659;, score=(train=0.615, test=0.495) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.001;, score=(train=0.690, test=0.546) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.001;, score=(train=0.617, test=0.478) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.001;, score=(train=0.564, test=0.574) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END var_smoothing=0.001;, score=(train=0.585, test=0.617) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.001;, score=(train=0.615, test=0.495) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.0008111308307896872;, score=(train=0.701, test=0.546) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.0008111308307896872;, score=(train=0.616, test=0.478) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.0008111308307896872;, score=(train=0.563, test=0.571) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.0008111308307896872;, score=(train=0.584, test=0.617) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.0008111308307896872;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.0006579332246575676;, score=(train=0.701, test=0.546) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.0006579332246575676;, score=(train=0.616, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.0006579332246575676;, score=(train=0.565, test=0.574) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.0006579332246575676;, score=(train=0.585, test=0.617) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.0006579332246575676;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.0005336699231206307;, score=(train=0.704, test=0.546) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.0005336699231206307;, score=(train=0.616, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.0005336699231206307;, score=(train=0.565, test=0.568) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.0005336699231206307;, score=(train=0.584, test=0.617) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.0005336699231206307;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.0004328761281083057;, score=(train=0.701, test=0.544) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.0004328761281083057;, score=(train=0.616, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.0004328761281083057;, score=(train=0.565, test=0.566) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.0004328761281083057;, score=(train=0.584, test=0.617) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.0004328761281083057;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.0003511191734215131;, score=(train=0.707, test=0.544) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.0003511191734215131;, score=(train=0.617, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.0003511191734215131;, score=(train=0.565, test=0.566) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.0003511191734215131;, score=(train=0.583, test=0.617) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.0003511191734215131;, score=(train=0.614, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.0002848035868435802;, score=(train=0.712, test=0.544) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.0002848035868435802;, score=(train=0.617, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.0002848035868435802;, score=(train=0.566, test=0.563) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.0002848035868435802;, score=(train=0.583, test=0.617) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.0002848035868435802;, score=(train=0.614, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.0002310129700083158;, score=(train=0.712, test=0.544) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.0002310129700083158;, score=(train=0.617, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.0002310129700083158;, score=(train=0.566, test=0.563) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.0002310129700083158;, score=(train=0.584, test=0.617) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.0002310129700083158;, score=(train=0.614, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.0001873817422860383;, score=(train=0.720, test=0.544) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.0001873817422860383;, score=(train=0.617, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.0001873817422860383;, score=(train=0.565, test=0.560) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.0001873817422860383;, score=(train=0.584, test=0.617) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.0001873817422860383;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.0001519911082952933;, score=(train=0.723, test=0.544) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.0001519911082952933;, score=(train=0.617, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.0001519911082952933;, score=(train=0.566, test=0.560) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.0001519911082952933;, score=(train=0.583, test=0.617) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.0001519911082952933;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.0001232846739442066;, score=(train=0.726, test=0.544) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.0001232846739442066;, score=(train=0.617, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.0001232846739442066;, score=(train=0.565, test=0.574) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.0001232846739442066;, score=(train=0.582, test=0.617) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.0001232846739442066;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=0.0001;, score=(train=0.726, test=0.538) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=0.0001;, score=(train=0.617, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=0.0001;, score=(train=0.565, test=0.577) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=0.0001;, score=(train=0.582, test=0.617) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=0.0001;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=8.111308307896872e-05;, score=(train=0.731, test=0.538) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=8.111308307896872e-05;, score=(train=0.616, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=8.111308307896872e-05;, score=(train=0.566, test=0.577) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=8.111308307896872e-05;, score=(train=0.582, test=0.617) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=8.111308307896872e-05;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=6.579332246575683e-05;, score=(train=0.734, test=0.536) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=6.579332246575683e-05;, score=(train=0.616, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=6.579332246575683e-05;, score=(train=0.566, test=0.587) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=6.579332246575683e-05;, score=(train=0.581, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=6.579332246575683e-05;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=5.3366992312063123e-05;, score=(train=0.739, test=0.536) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=5.3366992312063123e-05;, score=(train=0.616, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=5.3366992312063123e-05;, score=(train=0.566, test=0.604) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=5.3366992312063123e-05;, score=(train=0.581, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=5.3366992312063123e-05;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=4.328761281083062e-05;, score=(train=0.742, test=0.536) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=4.328761281083062e-05;, score=(train=0.616, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=4.328761281083062e-05;, score=(train=0.567, test=0.617) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=4.328761281083062e-05;, score=(train=0.582, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=4.328761281083062e-05;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=3.511191734215127e-05;, score=(train=0.742, test=0.536) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=3.511191734215127e-05;, score=(train=0.617, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=3.511191734215127e-05;, score=(train=0.567, test=0.617) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=3.511191734215127e-05;, score=(train=0.581, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=3.511191734215127e-05;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=2.848035868435799e-05;, score=(train=0.742, test=0.536) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=2.848035868435799e-05;, score=(train=0.617, test=0.475) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END var_smoothing=2.848035868435799e-05;, score=(train=0.567, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=2.848035868435799e-05;, score=(train=0.581, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=2.848035868435799e-05;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=2.310129700083158e-05;, score=(train=0.742, test=0.536) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=2.310129700083158e-05;, score=(train=0.617, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=2.310129700083158e-05;, score=(train=0.565, test=0.615) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=2.310129700083158e-05;, score=(train=0.581, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=2.310129700083158e-05;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1.873817422860383e-05;, score=(train=0.745, test=0.536) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1.873817422860383e-05;, score=(train=0.617, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1.873817422860383e-05;, score=(train=0.566, test=0.617) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1.873817422860383e-05;, score=(train=0.581, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1.873817422860383e-05;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1.5199110829529332e-05;, score=(train=0.745, test=0.536) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1.5199110829529332e-05;, score=(train=0.617, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1.5199110829529332e-05;, score=(train=0.566, test=0.617) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1.5199110829529332e-05;, score=(train=0.582, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1.5199110829529332e-05;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1.2328467394420658e-05;, score=(train=0.742, test=0.536) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1.2328467394420658e-05;, score=(train=0.617, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1.2328467394420658e-05;, score=(train=0.566, test=0.612) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1.2328467394420658e-05;, score=(train=0.581, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1.2328467394420658e-05;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1e-05;, score=(train=0.739, test=0.536) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1e-05;, score=(train=0.617, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1e-05;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1e-05;, score=(train=0.581, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1e-05;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=8.111308307896873e-06;, score=(train=0.739, test=0.533) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=8.111308307896873e-06;, score=(train=0.617, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=8.111308307896873e-06;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=8.111308307896873e-06;, score=(train=0.581, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=8.111308307896873e-06;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=6.579332246575683e-06;, score=(train=0.736, test=0.533) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=6.579332246575683e-06;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=6.579332246575683e-06;, score=(train=0.566, test=0.615) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=6.579332246575683e-06;, score=(train=0.581, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=6.579332246575683e-06;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=5.336699231206313e-06;, score=(train=0.736, test=0.533) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=5.336699231206313e-06;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=5.336699231206313e-06;, score=(train=0.566, test=0.612) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=5.336699231206313e-06;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=5.336699231206313e-06;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=4.328761281083053e-06;, score=(train=0.736, test=0.530) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=4.328761281083053e-06;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=4.328761281083053e-06;, score=(train=0.566, test=0.612) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=4.328761281083053e-06;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=4.328761281083053e-06;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=3.5111917342151275e-06;, score=(train=0.736, test=0.530) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=3.5111917342151275e-06;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=3.5111917342151275e-06;, score=(train=0.566, test=0.612) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=3.5111917342151275e-06;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=3.5111917342151275e-06;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=2.848035868435799e-06;, score=(train=0.734, test=0.530) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=2.848035868435799e-06;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=2.848035868435799e-06;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=2.848035868435799e-06;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=2.848035868435799e-06;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=2.310129700083158e-06;, score=(train=0.734, test=0.533) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=2.310129700083158e-06;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=2.310129700083158e-06;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=2.310129700083158e-06;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=2.310129700083158e-06;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1.873817422860383e-06;, score=(train=0.734, test=0.536) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1.873817422860383e-06;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1.873817422860383e-06;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1.873817422860383e-06;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1.873817422860383e-06;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1.519911082952933e-06;, score=(train=0.734, test=0.536) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1.519911082952933e-06;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1.519911082952933e-06;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1.519911082952933e-06;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1.519911082952933e-06;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1.232846739442066e-06;, score=(train=0.734, test=0.536) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1.232846739442066e-06;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1.232846739442066e-06;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1.232846739442066e-06;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1.232846739442066e-06;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1e-06;, score=(train=0.731, test=0.536) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1e-06;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1e-06;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1e-06;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1e-06;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=8.111308307896872e-07;, score=(train=0.728, test=0.533) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END var_smoothing=8.111308307896872e-07;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=8.111308307896872e-07;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=8.111308307896872e-07;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=8.111308307896872e-07;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=6.579332246575682e-07;, score=(train=0.728, test=0.533) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=6.579332246575682e-07;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=6.579332246575682e-07;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=6.579332246575682e-07;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=6.579332246575682e-07;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=5.336699231206313e-07;, score=(train=0.726, test=0.533) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=5.336699231206313e-07;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=5.336699231206313e-07;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=5.336699231206313e-07;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=5.336699231206313e-07;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=4.3287612810830526e-07;, score=(train=0.726, test=0.533) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=4.3287612810830526e-07;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=4.3287612810830526e-07;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=4.3287612810830526e-07;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=4.3287612810830526e-07;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=3.5111917342151277e-07;, score=(train=0.726, test=0.533) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=3.5111917342151277e-07;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=3.5111917342151277e-07;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=3.5111917342151277e-07;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=3.5111917342151277e-07;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=2.848035868435799e-07;, score=(train=0.726, test=0.533) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=2.848035868435799e-07;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=2.848035868435799e-07;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=2.848035868435799e-07;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=2.848035868435799e-07;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=2.310129700083158e-07;, score=(train=0.726, test=0.533) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=2.310129700083158e-07;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=2.310129700083158e-07;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=2.310129700083158e-07;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=2.310129700083158e-07;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1.873817422860383e-07;, score=(train=0.726, test=0.530) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1.873817422860383e-07;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1.873817422860383e-07;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1.873817422860383e-07;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1.873817422860383e-07;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1.519911082952933e-07;, score=(train=0.726, test=0.530) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1.519911082952933e-07;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1.519911082952933e-07;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1.519911082952933e-07;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1.519911082952933e-07;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1.232846739442066e-07;, score=(train=0.726, test=0.530) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1.232846739442066e-07;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1.232846739442066e-07;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1.232846739442066e-07;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1.232846739442066e-07;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1e-07;, score=(train=0.726, test=0.530) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1e-07;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1e-07;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1e-07;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1e-07;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=8.111308307896873e-08;, score=(train=0.726, test=0.530) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=8.111308307896873e-08;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=8.111308307896873e-08;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=8.111308307896873e-08;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=8.111308307896873e-08;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=6.579332246575682e-08;, score=(train=0.726, test=0.530) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=6.579332246575682e-08;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=6.579332246575682e-08;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=6.579332246575682e-08;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=6.579332246575682e-08;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=5.336699231206302e-08;, score=(train=0.726, test=0.530) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=5.336699231206302e-08;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=5.336699231206302e-08;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=5.336699231206302e-08;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=5.336699231206302e-08;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=4.3287612810830526e-08;, score=(train=0.726, test=0.530) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=4.3287612810830526e-08;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=4.3287612810830526e-08;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=4.3287612810830526e-08;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=4.3287612810830526e-08;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=3.5111917342151277e-08;, score=(train=0.726, test=0.530) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=3.5111917342151277e-08;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=3.5111917342151277e-08;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=3.5111917342151277e-08;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=3.5111917342151277e-08;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=2.848035868435799e-08;, score=(train=0.726, test=0.530) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=2.848035868435799e-08;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=2.848035868435799e-08;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=2.848035868435799e-08;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=2.848035868435799e-08;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=2.310129700083158e-08;, score=(train=0.726, test=0.530) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=2.310129700083158e-08;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=2.310129700083158e-08;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=2.310129700083158e-08;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=2.310129700083158e-08;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1.873817422860383e-08;, score=(train=0.726, test=0.530) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1.873817422860383e-08;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1.873817422860383e-08;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1.873817422860383e-08;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1.873817422860383e-08;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1.519911082952933e-08;, score=(train=0.726, test=0.530) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1.519911082952933e-08;, score=(train=0.619, test=0.475) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END var_smoothing=1.519911082952933e-08;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1.519911082952933e-08;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1.519911082952933e-08;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1.232846739442066e-08;, score=(train=0.726, test=0.530) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1.232846739442066e-08;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1.232846739442066e-08;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1.232846739442066e-08;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1.232846739442066e-08;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1e-08;, score=(train=0.726, test=0.530) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1e-08;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1e-08;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1e-08;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1e-08;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=8.111308307896856e-09;, score=(train=0.726, test=0.530) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=8.111308307896856e-09;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=8.111308307896856e-09;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=8.111308307896856e-09;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=8.111308307896856e-09;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=6.579332246575682e-09;, score=(train=0.726, test=0.530) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=6.579332246575682e-09;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=6.579332246575682e-09;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=6.579332246575682e-09;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=6.579332246575682e-09;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=5.336699231206302e-09;, score=(train=0.726, test=0.530) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=5.336699231206302e-09;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=5.336699231206302e-09;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=5.336699231206302e-09;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=5.336699231206302e-09;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=4.328761281083061e-09;, score=(train=0.726, test=0.530) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=4.328761281083061e-09;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=4.328761281083061e-09;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=4.328761281083061e-09;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=4.328761281083061e-09;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=3.5111917342151273e-09;, score=(train=0.726, test=0.530) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=3.5111917342151273e-09;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=3.5111917342151273e-09;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=3.5111917342151273e-09;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=3.5111917342151273e-09;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=2.848035868435805e-09;, score=(train=0.726, test=0.530) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=2.848035868435805e-09;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=2.848035868435805e-09;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=2.848035868435805e-09;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=2.848035868435805e-09;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=2.310129700083158e-09;, score=(train=0.726, test=0.530) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=2.310129700083158e-09;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=2.310129700083158e-09;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=2.310129700083158e-09;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=2.310129700083158e-09;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1.873817422860387e-09;, score=(train=0.726, test=0.530) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1.873817422860387e-09;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1.873817422860387e-09;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1.873817422860387e-09;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1.873817422860387e-09;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1.519911082952933e-09;, score=(train=0.726, test=0.530) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1.519911082952933e-09;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1.519911082952933e-09;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1.519911082952933e-09;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1.519911082952933e-09;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1.2328467394420635e-09;, score=(train=0.726, test=0.530) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1.2328467394420635e-09;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1.2328467394420635e-09;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1.2328467394420635e-09;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1.2328467394420635e-09;, score=(train=0.615, test=0.492) total time=   0.0s\n",
      "[CV 1/5] END var_smoothing=1e-09;, score=(train=0.726, test=0.530) total time=   0.0s\n",
      "[CV 2/5] END var_smoothing=1e-09;, score=(train=0.619, test=0.475) total time=   0.0s\n",
      "[CV 3/5] END var_smoothing=1e-09;, score=(train=0.566, test=0.609) total time=   0.0s\n",
      "[CV 4/5] END var_smoothing=1e-09;, score=(train=0.580, test=0.615) total time=   0.0s\n",
      "[CV 5/5] END var_smoothing=1e-09;, score=(train=0.615, test=0.492) total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'var_smoothing': 4.328761281083062e-05}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "params = {\n",
    "    'var_smoothing':np.logspace(0,-9, num=100)\n",
    "}\n",
    "\n",
    "gs_NB = GridSearchCV(estimator=model, \n",
    "                 param_grid=params, \n",
    "                 verbose=3, \n",
    "                 refit=True,\n",
    "                 cv=tscv,  # change this to the splitter subject to test\n",
    "                 pre_dispatch=8,\n",
    "                 return_train_score=True,\n",
    "                 scoring='accuracy')\n",
    "\n",
    "gs_NB.fit(X_train, y_train)\n",
    "gs_NB.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d70f37",
   "metadata": {},
   "source": [
    "#  Logistic  Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d509701a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_LR: 0.4764142483147348 (+/- 0.05037519949357786\n",
      "\n",
      "R2_LR: 0.06870881433398453 (+/- 0.18798167258377435\n",
      "\n",
      "Accuracy for each folder: [0.75409836 0.78961749 0.79781421 0.82786885 0.68306011]\n",
      "\n",
      "Mean Accuracy 0.7704918032786885\n",
      "\n",
      "roc_auc 0.9186506597455887\n",
      "\n",
      "max_error -1.0\n",
      "\n",
      "F1Score For Each Folder [0.26666667 0.         0.         0.76142132 0.21818182]\n",
      "\n",
      "F1Score Mean 0.24925396092908786\n",
      "\n",
      " clasification report for Classification LR:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.85       444\n",
      "           1       0.85      0.88      0.87       496\n",
      "\n",
      "    accuracy                           0.86       940\n",
      "   macro avg       0.86      0.86      0.86       940\n",
      "weighted avg       0.86      0.86      0.86       940\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_LR = LogisticRegression(C=10,penalty= 'l2')\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "\n",
    "rmse_LR = np.sqrt(-cross_val_score(model_LR, X_train, y_train, cv=tscv, scoring='neg_mean_squared_error'))\n",
    "R2_LR = cross_val_score(model_LR, X_train, y_train, cv=tscv, scoring='r2')\n",
    "roc_auc_LR = cross_val_score(model_LR, X_train, y_train, cv=tscv, scoring='roc_auc')\n",
    "Accuracy_LR = cross_val_score(model_LR, X_train, y_train, cv=tscv)\n",
    "max_error_LR = cross_val_score(model_LR, X_train, y_train, cv=tscv, scoring='max_error')\n",
    "f1Score_LR=cross_val_score(model, X_train, y_train, cv=tscv, scoring='f1')\n",
    "\n",
    "\n",
    "\n",
    "print(f\"RMSE_LR: {rmse_LR.mean()} (+/- {rmse_LR.std()}\")\n",
    "print(f\"\\nR2_LR: {R2_LR.mean()} (+/- {R2_LR.std()}\")\n",
    "print(f\"\\nAccuracy for each folder: {Accuracy_LR}\")\n",
    "print(f\"\\nMean Accuracy {Accuracy_LR.mean()}\")\n",
    "print(f\"\\nroc_auc {roc_auc_LR.mean()}\")\n",
    "print(f\"\\nmax_error {max_error_LR.mean()}\")\n",
    "print(f\"\\nF1Score For Each Folder {f1Score_LR}\")\n",
    "print(f\"\\nF1Score Mean {f1Score_LR.mean()}\")\n",
    "\n",
    "model_LR.fit(X_train, y_train)\n",
    "y_predLR=model_LR.predict(X_test)\n",
    "print ('\\n clasification report for Classification LR:\\n', classification_report(y_test,y_predLR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cce413",
   "metadata": {},
   "source": [
    "# GridSearch Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "169af1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['C', 'class_weight', 'dual', 'fit_intercept', 'intercept_scaling', 'l1_ratio', 'max_iter', 'multi_class', 'n_jobs', 'penalty', 'random_state', 'solver', 'tol', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LR.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d215fe71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1000.0, 'class_weight': 'balanced', 'penalty': 'l2'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LR = LogisticRegression()\n",
    "\n",
    "params={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\",\"elasticnet\"],\"class_weight\":[\"dict\",\"balanced\"] }\n",
    "\n",
    "gs_LR = GridSearchCV(estimator=model_LR, \n",
    "                 param_grid=params, \n",
    "                 verbose=1, \n",
    "                 n_jobs=4,\n",
    "                 cv=tscv,  # change this to the splitter subject to test\n",
    "                 pre_dispatch=8,\n",
    "                 return_train_score=True,\n",
    "                 scoring='accuracy')\n",
    "\n",
    "gs_LR.fit(X_train, y_train)\n",
    "gs_LR.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f683d06",
   "metadata": {},
   "source": [
    "# SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c251fac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.462 total time=   0.0s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.519 total time=   0.0s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.579 total time=   0.0s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.615 total time=   0.1s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.505 total time=   0.2s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.462 total time=   0.0s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.519 total time=   0.0s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.579 total time=   0.0s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.615 total time=   0.1s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.505 total time=   0.2s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.462 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.519 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.579 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.615 total time=   0.1s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.505 total time=   0.2s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.462 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.519 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.579 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.615 total time=   0.1s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.505 total time=   0.2s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.462 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.519 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.579 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.615 total time=   0.1s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.505 total time=   0.2s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.516 total time=   0.0s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.533 total time=   0.0s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.478 total time=   0.0s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.533 total time=   0.1s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.519 total time=   0.2s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.462 total time=   0.0s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.514 total time=   0.0s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.560 total time=   0.0s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.615 total time=   0.1s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.620 total time=   0.2s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.462 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.519 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.579 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.615 total time=   0.1s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.505 total time=   0.2s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.462 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.519 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.579 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.615 total time=   0.1s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.505 total time=   0.2s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.462 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.519 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.579 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.615 total time=   0.1s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.505 total time=   0.2s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.503 total time=   0.0s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.577 total time=   0.0s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.533 total time=   0.0s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.546 total time=   0.1s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.495 total time=   0.2s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.577 total time=   0.0s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.634 total time=   0.0s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.634 total time=   0.0s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.650 total time=   0.1s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.527 total time=   0.1s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.462 total time=   0.0s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.604 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.658 total time=   0.1s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.560 total time=   0.2s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.462 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.522 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.579 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.615 total time=   0.1s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.505 total time=   0.2s\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.462 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.519 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.579 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.615 total time=   0.1s\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.505 total time=   0.2s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.492 total time=   0.0s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.585 total time=   0.0s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.585 total time=   0.0s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.544 total time=   0.1s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.495 total time=   0.2s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.574 total time=   0.0s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.740 total time=   0.0s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.730 total time=   0.0s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.781 total time=   0.0s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.541 total time=   0.1s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.617 total time=   0.0s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.708 total time=   0.0s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.648 total time=   0.0s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.683 total time=   0.1s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.560 total time=   0.1s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.462 total time=   0.0s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.505 total time=   0.0s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.620 total time=   0.0s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.689 total time=   0.1s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.560 total time=   0.2s\n",
      "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.462 total time=   0.0s\n",
      "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.522 total time=   0.0s\n",
      "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.579 total time=   0.0s\n",
      "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.615 total time=   0.1s\n",
      "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.505 total time=   0.2s\n",
      "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.582 total time=   0.0s\n",
      "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.590 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.527 total time=   0.1s\n",
      "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.495 total time=   0.2s\n",
      "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.552 total time=   0.0s\n",
      "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.686 total time=   0.0s\n",
      "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.716 total time=   0.0s\n",
      "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.661 total time=   0.1s\n",
      "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.648 total time=   0.1s\n",
      "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.738 total time=   0.0s\n",
      "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.765 total time=   0.0s\n",
      "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.795 total time=   0.0s\n",
      "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.631 total time=   0.1s\n",
      "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.634 total time=   0.0s\n",
      "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.719 total time=   0.0s\n",
      "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.675 total time=   0.0s\n",
      "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.705 total time=   0.1s\n",
      "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.623 total time=   0.1s\n",
      "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.462 total time=   0.0s\n",
      "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.505 total time=   0.0s\n",
      "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.617 total time=   0.0s\n",
      "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.699 total time=   0.1s\n",
      "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.571 total time=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "# defining parameter range\n",
    "params = {'C': [0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf']}\n",
    "\n",
    "grid = GridSearchCV(SVC(), params, refit = True, verbose = 3, cv=tscv)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "509f5148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_SVM: 0.4930293184112654 (+/- 0.0668062481619831\n",
      "\n",
      "R2_SVM: -0.0055873537378615225 (+/- 0.2679544561681145\n",
      "\n",
      "Accuracy for each folder: [0.73770492 0.83333333 0.76502732 0.79508197 0.63114754]\n",
      "\n",
      "Mean Accuracy 0.7524590163934427\n",
      "\n",
      "roc_auc 0.9062803388021738\n",
      "\n",
      "max_error -1.0\n",
      "\n",
      "F1Score For Each Folder [0.77358491 0.83646113 0.75706215 0.85714286 0.42553191]\n",
      "\n",
      "F1Score Mean 0.7299565901189738\n",
      "\n",
      " clasification report for Classification SVM:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76       444\n",
      "           1       0.77      0.83      0.80       496\n",
      "\n",
      "    accuracy                           0.78       940\n",
      "   macro avg       0.78      0.78      0.78       940\n",
      "weighted avg       0.78      0.78      0.78       940\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelSVM = SVC(C=1000,gamma=0.01,kernel='rbf')\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "rmse_SVM = np.sqrt(-cross_val_score(modelSVM, X_train, y_train, cv=tscv, scoring='neg_mean_squared_error'))\n",
    "R2_SVM = cross_val_score(modelSVM, X_train, y_train, cv=tscv, scoring='r2')\n",
    "roc_auc_SVM = cross_val_score(modelSVM, X_train, y_train, cv=tscv, scoring='roc_auc')\n",
    "Accuracy_SVM = cross_val_score(modelSVM, X_train, y_train, cv=tscv)\n",
    "max_error_SVM = cross_val_score(modelSVM, X_train, y_train, cv=tscv, scoring='max_error')\n",
    "f1Score_SVM=cross_val_score(modelSVM, X_train, y_train, cv=tscv, scoring='f1')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"RMSE_SVM: {rmse_SVM.mean()} (+/- {rmse_SVM.std()}\")\n",
    "print(f\"\\nR2_SVM: {R2_SVM.mean()} (+/- {R2_SVM.std()}\")\n",
    "print(f\"\\nAccuracy for each folder: {Accuracy_SVM}\")\n",
    "print(f\"\\nMean Accuracy {Accuracy_SVM.mean()}\")\n",
    "print(f\"\\nroc_auc {roc_auc_SVM.mean()}\")\n",
    "print(f\"\\nmax_error {max_error_SVM.mean()}\")\n",
    "print(f\"\\nF1Score For Each Folder {f1Score_SVM}\")\n",
    "print(f\"\\nF1Score Mean {f1Score_SVM.mean()}\")\n",
    "\n",
    "modelSVM.fit(X_train, y_train)\n",
    "y_predSVM=modelSVM.predict(X_test)\n",
    "print ('\\n clasification report for Classification SVM:\\n', classification_report(y_test,y_predSVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed3429e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Price               0\n",
       "Active Addresses    0\n",
       "New Addresses       0\n",
       "NVT Ratio           0\n",
       "NVT Signal          0\n",
       "                   ..\n",
       "Returns_lag_1       0\n",
       "Returns_lag_2       0\n",
       "Returns_lag_3       0\n",
       "Returns_lag_4       0\n",
       "Returns_lag_5       0\n",
       "Length: 144, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe62a36",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fb1145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea2cea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model() :\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64,input_shape=(96,),  activation = 'relu'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1527700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model() :\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64,input_shape=(144,),  activation = 'relu'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579aa04e",
   "metadata": {},
   "source": [
    "# Tuning the epoch number and the batch size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d59e730",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(model=create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb826d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=tscv)\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e82f97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.672678 using {'batch_size': 20, 'epochs': 100}\n",
      "0.554645 (0.054945) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.640984 (0.027026) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.656284 (0.069710) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.526230 (0.068917) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.595628 (0.063444) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.672678 (0.033836) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.532240 (0.047525) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.570492 (0.050981) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.658470 (0.036534) with: {'batch_size': 40, 'epochs': 100}\n",
      "0.529508 (0.040724) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.562295 (0.064689) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.614208 (0.041881) with: {'batch_size': 60, 'epochs': 100}\n",
      "0.529508 (0.063005) with: {'batch_size': 80, 'epochs': 10}\n",
      "0.584699 (0.065688) with: {'batch_size': 80, 'epochs': 50}\n",
      "0.637158 (0.051098) with: {'batch_size': 80, 'epochs': 100}\n",
      "0.518579 (0.057918) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.556831 (0.062098) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.602186 (0.047594) with: {'batch_size': 100, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f991c33f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-148-d6c5a1865af8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbatchsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'batch_size'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'epochs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'batch_size'"
     ]
    }
   ],
   "source": [
    "batchsize=grid_result.best_params_['batch_size']\n",
    "epoch=grid_result.best_params_['epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1a255ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(model=create_model, verbose=0,batch_size = batchsize, epochs = epoch )\n",
    "tscv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "701b66c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results=cross_val_score(model,X_train,y_train,cv=tscv,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2105da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each folder: [0.66393443 0.63661202 0.67486339 0.67759563 0.63114754]\n",
      "\n",
      "Accuracy for each folder: 0.6568306010928963\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nAccuracy for each folder: {cv_results}\")\n",
    "print(f\"\\nAccuracy for each folder: {cv_results.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425b31a9",
   "metadata": {},
   "source": [
    "# Tuning the optimization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca72d8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    " def create_model() :\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64,input_shape=(366,),  activation = 'relu'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35b4d0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.648087 using {'optimizer': 'RMSprop'}\n",
      "0.635519 (0.042243) with: {'optimizer': 'SGD'}\n",
      "0.648087 (0.044675) with: {'optimizer': 'RMSprop'}\n",
      "0.638798 (0.052510) with: {'optimizer': 'Adagrad'}\n",
      "0.640437 (0.044076) with: {'optimizer': 'Adadelta'}\n",
      "0.633880 (0.067702) with: {'optimizer': 'Adam'}\n",
      "0.627869 (0.059746) with: {'optimizer': 'Adamax'}\n",
      "0.627869 (0.043352) with: {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=tscv)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e70a1b9",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4588ebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the Data for LSTM\n",
    "# reshaping into 3D Array\n",
    "X_train_LSTM = np.array(scaled_X_train).reshape(len(scaled_X_train),1,len(list(X.keys())))\n",
    "X_test_LSTM = np.array(scaled_X_test).reshape(len(scaled_X_test),1,len(list(X.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0bbab423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import InputLayer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9c09d00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLSTMModel(optimizer,activation,loss):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(units = 256, input_shape = (X_train_LSTM.shape[1],X_train_LSTM.shape[2]),\n",
    "                   return_sequences = True)) \n",
    "    model.add(Dropout(0.4, seed = seed_value))\n",
    "\n",
    "    model.add(LSTM(units = 256, return_sequences = True))\n",
    "    model.add(Dropout(0.4, seed = seed_value))\n",
    "\n",
    "    model.add(LSTM(units = 64, return_sequences=False))\n",
    "    model.add(Dropout(0.4, seed = seed_value))\n",
    "\n",
    "    model.add(Dense(64,  activation = activation))\n",
    "  \n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "  \n",
    "    model.compile(optimizer = optimizer, loss = loss ,metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "624a694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param_LSTM = {\n",
    "    'batch_size': [10],\n",
    "    'epochs': [10],   \n",
    "    'activation': ['relu', 'linear' ],\n",
    "    'optimizer': ['SGD', 'Adamax'],\n",
    "    'loss': ['logcosh']\n",
    "    \n",
    "#     'batch_size': [10,20,40,60,80,128,200,256,348],\n",
    "#     'epochs': [10,15,30,40,50,100],   \n",
    "#     'learning_rate':[0.001,0.01,0.1,0.0001],\n",
    "#     'optimizer': ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam'],\n",
    "#     'loss': ['logcosh', 'mae', 'mse', 'hinge','squared_hinge'],\n",
    "#     'activation': ['relu', 'linear','sigmoid','hard_sigmoid', 'tanh'],\n",
    "#     'dropout_rate':[0.1,0.2,0.4,0.6]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cdc57c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import  Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "30a6aee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LSTM =KerasClassifier(build_fn=createLSTMModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3444d8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "GridLSTM = GridSearchCV(estimator=model_LSTM,\n",
    "                     param_grid=grid_param_LSTM,\n",
    "                     scoring='accuracy',\n",
    "                     cv=tscv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0ce67a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "37/37 [==============================] - 3s 6ms/step - loss: 0.1199 - accuracy: 0.5761\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1195 - accuracy: 0.6223\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1191 - accuracy: 0.6223\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1186 - accuracy: 0.6223\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1182 - accuracy: 0.6223\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1177 - accuracy: 0.6223\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1173 - accuracy: 0.6223\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1170 - accuracy: 0.6223\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1166 - accuracy: 0.6223\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1163 - accuracy: 0.6223\n",
      "Epoch 1/10\n",
      "74/74 [==============================] - 4s 6ms/step - loss: 0.1201 - accuracy: 0.4973\n",
      "Epoch 2/10\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1200 - accuracy: 0.5422\n",
      "Epoch 3/10\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1199 - accuracy: 0.5422\n",
      "Epoch 4/10\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1198 - accuracy: 0.5422\n",
      "Epoch 5/10\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1198 - accuracy: 0.5422\n",
      "Epoch 6/10\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1197 - accuracy: 0.5422\n",
      "Epoch 7/10\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1196 - accuracy: 0.5422\n",
      "Epoch 8/10\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1196 - accuracy: 0.5422\n",
      "Epoch 9/10\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1195 - accuracy: 0.5422\n",
      "Epoch 10/10\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1195 - accuracy: 0.5422\n",
      "Epoch 1/10\n",
      "110/110 [==============================] - 3s 6ms/step - loss: 0.1201 - accuracy: 0.5145\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1200 - accuracy: 0.5345\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.1199 - accuracy: 0.5345\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1198 - accuracy: 0.5345\n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1198 - accuracy: 0.5345\n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1197 - accuracy: 0.5345\n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1197 - accuracy: 0.5345\n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1196 - accuracy: 0.5345\n",
      "Epoch 9/10\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1196 - accuracy: 0.5345\n",
      "Epoch 10/10\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1196 - accuracy: 0.5345\n",
      "Epoch 1/10\n",
      "147/147 [==============================] - 4s 6ms/step - loss: 0.1200 - accuracy: 0.5327\n",
      "Epoch 2/10\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 0.1198 - accuracy: 0.5457\n",
      "Epoch 3/10\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 0.1196 - accuracy: 0.5457\n",
      "Epoch 4/10\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 0.1195 - accuracy: 0.5457\n",
      "Epoch 5/10\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 0.1193 - accuracy: 0.5457\n",
      "Epoch 6/10\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 0.1193 - accuracy: 0.5457\n",
      "Epoch 7/10\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 0.1192 - accuracy: 0.5457\n",
      "Epoch 8/10\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 0.1192 - accuracy: 0.5457\n",
      "Epoch 9/10\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 0.1191 - accuracy: 0.5457\n",
      "Epoch 10/10\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 0.1191 - accuracy: 0.5457\n",
      "Epoch 1/10\n",
      "184/184 [==============================] - 4s 6ms/step - loss: 0.1199 - accuracy: 0.5491\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.1195 - accuracy: 0.5595\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.1192 - accuracy: 0.5595\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 1s 5ms/step - loss: 0.1189 - accuracy: 0.5595\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 1s 5ms/step - loss: 0.1187 - accuracy: 0.5595\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.1186 - accuracy: 0.5595\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.1185 - accuracy: 0.5595\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.1184 - accuracy: 0.5595\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.1184 - accuracy: 0.5595\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.1183 - accuracy: 0.5595\n",
      "Epoch 1/10\n",
      "37/37 [==============================] - 4s 7ms/step - loss: 0.1177 - accuracy: 0.6223\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1126 - accuracy: 0.6223\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1121 - accuracy: 0.6223\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1120 - accuracy: 0.6223\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1121 - accuracy: 0.6223\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1123 - accuracy: 0.6223\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1111 - accuracy: 0.6223\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1102 - accuracy: 0.6223\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1115 - accuracy: 0.6223\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1123 - accuracy: 0.6223\n",
      "Epoch 1/10\n",
      "74/74 [==============================] - 4s 7ms/step - loss: 0.1200 - accuracy: 0.5123\n",
      "Epoch 2/10\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.1192 - accuracy: 0.5422\n",
      "Epoch 3/10\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.1183 - accuracy: 0.5422\n",
      "Epoch 4/10\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.1175 - accuracy: 0.5490\n",
      "Epoch 5/10\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.1160 - accuracy: 0.5640\n",
      "Epoch 6/10\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.1158 - accuracy: 0.5790\n",
      "Epoch 7/10\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.1149 - accuracy: 0.5913\n",
      "Epoch 8/10\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.1149 - accuracy: 0.5831\n",
      "Epoch 9/10\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.1145 - accuracy: 0.5817\n",
      "Epoch 10/10\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.1139 - accuracy: 0.5954\n",
      "Epoch 1/10\n",
      "110/110 [==============================] - 3s 6ms/step - loss: 0.1202 - accuracy: 0.5045\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 1s 7ms/step - loss: 0.1197 - accuracy: 0.5345\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 1s 7ms/step - loss: 0.1194 - accuracy: 0.5345\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 1s 7ms/step - loss: 0.1191 - accuracy: 0.5345\n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 1s 7ms/step - loss: 0.1186 - accuracy: 0.5345\n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 1s 7ms/step - loss: 0.1183 - accuracy: 0.5336\n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 1s 7ms/step - loss: 0.1174 - accuracy: 0.5491\n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 1s 7ms/step - loss: 0.1178 - accuracy: 0.5409\n",
      "Epoch 9/10\n",
      "110/110 [==============================] - 1s 7ms/step - loss: 0.1167 - accuracy: 0.5436\n",
      "Epoch 10/10\n",
      "110/110 [==============================] - 1s 7ms/step - loss: 0.1164 - accuracy: 0.5455\n",
      "Epoch 1/10\n",
      "147/147 [==============================] - 5s 7ms/step - loss: 0.1194 - accuracy: 0.5457\n",
      "Epoch 2/10\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1190 - accuracy: 0.5457\n",
      "Epoch 3/10\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1185 - accuracy: 0.5457\n",
      "Epoch 4/10\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1185 - accuracy: 0.5457\n",
      "Epoch 5/10\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.1177 - accuracy: 0.5464\n",
      "Epoch 6/10\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1175 - accuracy: 0.5587\n",
      "Epoch 7/10\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1173 - accuracy: 0.5539\n",
      "Epoch 8/10\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1170 - accuracy: 0.5539\n",
      "Epoch 9/10\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1161 - accuracy: 0.5778\n",
      "Epoch 10/10\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1154 - accuracy: 0.5819\n",
      "Epoch 1/10\n",
      "184/184 [==============================] - 4s 7ms/step - loss: 0.1190 - accuracy: 0.5529\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.1181 - accuracy: 0.5595\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.1175 - accuracy: 0.5595\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.1177 - accuracy: 0.5595\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1173 - accuracy: 0.5611\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.1162 - accuracy: 0.5682\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.1163 - accuracy: 0.5639\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.1160 - accuracy: 0.5781\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1143 - accuracy: 0.5781\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1141 - accuracy: 0.5884\n",
      "Epoch 1/10\n",
      "37/37 [==============================] - 3s 6ms/step - loss: 0.1198 - accuracy: 0.6033\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1190 - accuracy: 0.6223\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1183 - accuracy: 0.6223\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1176 - accuracy: 0.6223\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1171 - accuracy: 0.6223\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1166 - accuracy: 0.6223\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1161 - accuracy: 0.6223\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1157 - accuracy: 0.6223\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1154 - accuracy: 0.6223\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1151 - accuracy: 0.6223\n",
      "Epoch 1/10\n",
      "74/74 [==============================] - 4s 6ms/step - loss: 0.1200 - accuracy: 0.5327\n",
      "Epoch 2/10\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1198 - accuracy: 0.5422\n",
      "Epoch 3/10\n",
      "74/74 [==============================] - 0s 7ms/step - loss: 0.1197 - accuracy: 0.5422\n",
      "Epoch 4/10\n",
      "74/74 [==============================] - 0s 7ms/step - loss: 0.1196 - accuracy: 0.5422\n",
      "Epoch 5/10\n",
      "74/74 [==============================] - 0s 7ms/step - loss: 0.1195 - accuracy: 0.5422\n",
      "Epoch 6/10\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1194 - accuracy: 0.5422\n",
      "Epoch 7/10\n",
      "74/74 [==============================] - 0s 7ms/step - loss: 0.1194 - accuracy: 0.5422\n",
      "Epoch 8/10\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1193 - accuracy: 0.5422\n",
      "Epoch 9/10\n",
      "74/74 [==============================] - 0s 7ms/step - loss: 0.1193 - accuracy: 0.5422\n",
      "Epoch 10/10\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1192 - accuracy: 0.5422\n",
      "Epoch 1/10\n",
      "110/110 [==============================] - 3s 6ms/step - loss: 0.1200 - accuracy: 0.5309\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1198 - accuracy: 0.5345\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1198 - accuracy: 0.5345\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1197 - accuracy: 0.5345\n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1196 - accuracy: 0.5345\n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1196 - accuracy: 0.5345\n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1196 - accuracy: 0.5345\n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1195 - accuracy: 0.5345\n",
      "Epoch 9/10\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1195 - accuracy: 0.5345\n",
      "Epoch 10/10\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1195 - accuracy: 0.5345\n",
      "Epoch 1/10\n",
      "147/147 [==============================] - 4s 6ms/step - loss: 0.1199 - accuracy: 0.5389\n",
      "Epoch 2/10\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 0.1196 - accuracy: 0.5457\n",
      "Epoch 3/10\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 0.1194 - accuracy: 0.5457\n",
      "Epoch 4/10\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1192 - accuracy: 0.5457\n",
      "Epoch 5/10\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1191 - accuracy: 0.5457\n",
      "Epoch 6/10\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1191 - accuracy: 0.5457\n",
      "Epoch 7/10\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1191 - accuracy: 0.5457\n",
      "Epoch 8/10\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 0.1190 - accuracy: 0.5457\n",
      "Epoch 9/10\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1190 - accuracy: 0.5457\n",
      "Epoch 10/10\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 0.1190 - accuracy: 0.5457\n",
      "Epoch 1/10\n",
      "184/184 [==============================] - 4s 6ms/step - loss: 0.1197 - accuracy: 0.5508\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.1190 - accuracy: 0.5595\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.1187 - accuracy: 0.5595\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.1185 - accuracy: 0.5595\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.1183 - accuracy: 0.5595\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.1183 - accuracy: 0.5595\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.1183 - accuracy: 0.5595\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.1182 - accuracy: 0.5595\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.1182 - accuracy: 0.5595\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.1182 - accuracy: 0.5595\n",
      "Epoch 1/10\n",
      "37/37 [==============================] - 3s 8ms/step - loss: 0.1159 - accuracy: 0.6141\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1123 - accuracy: 0.6223\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1121 - accuracy: 0.6223\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1124 - accuracy: 0.6223\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1115 - accuracy: 0.6223\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1112 - accuracy: 0.6223\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1120 - accuracy: 0.6223\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 0s 8ms/step - loss: 0.1111 - accuracy: 0.6223\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1117 - accuracy: 0.6223\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1119 - accuracy: 0.6223\n",
      "Epoch 1/10\n",
      "74/74 [==============================] - 4s 7ms/step - loss: 0.1197 - accuracy: 0.5368\n",
      "Epoch 2/10\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.1188 - accuracy: 0.5422\n",
      "Epoch 3/10\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.1182 - accuracy: 0.5422\n",
      "Epoch 4/10\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.1169 - accuracy: 0.5450\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 1s 8ms/step - loss: 0.1156 - accuracy: 0.5545\n",
      "Epoch 6/10\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.1151 - accuracy: 0.5804\n",
      "Epoch 7/10\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.1150 - accuracy: 0.5831\n",
      "Epoch 8/10\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.1138 - accuracy: 0.5940\n",
      "Epoch 9/10\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.1133 - accuracy: 0.5954\n",
      "Epoch 10/10\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.1127 - accuracy: 0.5926\n",
      "Epoch 1/10\n",
      "110/110 [==============================] - 3s 6ms/step - loss: 0.1195 - accuracy: 0.5327\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1193 - accuracy: 0.5345\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1188 - accuracy: 0.5264\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1180 - accuracy: 0.5427\n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1177 - accuracy: 0.5491\n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 1s 7ms/step - loss: 0.1167 - accuracy: 0.5418\n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 1s 7ms/step - loss: 0.1160 - accuracy: 0.5445\n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 1s 7ms/step - loss: 0.1155 - accuracy: 0.5736\n",
      "Epoch 9/10\n",
      "110/110 [==============================] - 1s 7ms/step - loss: 0.1151 - accuracy: 0.5655\n",
      "Epoch 10/10\n",
      "110/110 [==============================] - 1s 7ms/step - loss: 0.1133 - accuracy: 0.5836\n",
      "Epoch 1/10\n",
      "147/147 [==============================] - 5s 7ms/step - loss: 0.1189 - accuracy: 0.5450\n",
      "Epoch 2/10\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1188 - accuracy: 0.5457\n",
      "Epoch 3/10\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1188 - accuracy: 0.5457\n",
      "Epoch 4/10\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1181 - accuracy: 0.5430\n",
      "Epoch 5/10\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1178 - accuracy: 0.5423\n",
      "Epoch 6/10\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1172 - accuracy: 0.5484\n",
      "Epoch 7/10\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1175 - accuracy: 0.5655\n",
      "Epoch 8/10\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1155 - accuracy: 0.5634\n",
      "Epoch 9/10\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.1151 - accuracy: 0.5791\n",
      "Epoch 10/10\n",
      "147/147 [==============================] - 1s 8ms/step - loss: 0.1131 - accuracy: 0.5819\n",
      "Epoch 1/10\n",
      "184/184 [==============================] - 5s 7ms/step - loss: 0.1185 - accuracy: 0.5513\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1180 - accuracy: 0.5595\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1177 - accuracy: 0.5595\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1173 - accuracy: 0.5595\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1168 - accuracy: 0.5595\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1160 - accuracy: 0.5753\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1148 - accuracy: 0.5764\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1146 - accuracy: 0.5808\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 1s 8ms/step - loss: 0.1139 - accuracy: 0.5868\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1134 - accuracy: 0.5802\n",
      "Epoch 1/10\n",
      "220/220 [==============================] - 4s 6ms/step - loss: 0.1199 - accuracy: 0.5432\n",
      "Epoch 2/10\n",
      "220/220 [==============================] - 1s 6ms/step - loss: 0.1195 - accuracy: 0.5505\n",
      "Epoch 3/10\n",
      "220/220 [==============================] - 1s 6ms/step - loss: 0.1193 - accuracy: 0.5505\n",
      "Epoch 4/10\n",
      "220/220 [==============================] - 1s 6ms/step - loss: 0.1191 - accuracy: 0.5505\n",
      "Epoch 5/10\n",
      "220/220 [==============================] - 1s 6ms/step - loss: 0.1190 - accuracy: 0.5505\n",
      "Epoch 6/10\n",
      "220/220 [==============================] - 1s 6ms/step - loss: 0.1189 - accuracy: 0.5505\n",
      "Epoch 7/10\n",
      "220/220 [==============================] - 1s 6ms/step - loss: 0.1188 - accuracy: 0.5505\n",
      "Epoch 8/10\n",
      "220/220 [==============================] - 1s 6ms/step - loss: 0.1188 - accuracy: 0.5505\n",
      "Epoch 9/10\n",
      "220/220 [==============================] - 1s 6ms/step - loss: 0.1188 - accuracy: 0.5505\n",
      "Epoch 10/10\n",
      "220/220 [==============================] - 1s 6ms/step - loss: 0.1188 - accuracy: 0.5505\n"
     ]
    }
   ],
   "source": [
    "grid_search =GridLSTM.fit(X_train_LSTM, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "67eba65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters=GridLSTM.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8e88fcce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'batch_size': 10,\n",
       " 'epochs': 10,\n",
       " 'loss': 'logcosh',\n",
       " 'optimizer': 'SGD'}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9d3defd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "act=best_parameters['activation']\n",
    "batch=best_parameters['batch_size']\n",
    "EPO=best_parameters['epochs']\n",
    "LOSS=best_parameters['loss']\n",
    "Opt=best_parameters['optimizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5d32dbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = GridLSTM.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "253fa434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5360655737704919"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "79c05144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "37/37 [==============================] - 4s 6ms/step - loss: 0.1199 - accuracy: 0.5924\n",
      "Epoch 2/30\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1195 - accuracy: 0.6223\n",
      "Epoch 3/30\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1190 - accuracy: 0.6223\n",
      "Epoch 4/30\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1186 - accuracy: 0.6223\n",
      "Epoch 5/30\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1181 - accuracy: 0.6223\n",
      "Epoch 6/30\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1177 - accuracy: 0.6223\n",
      "Epoch 7/30\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1173 - accuracy: 0.6223\n",
      "Epoch 8/30\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1170 - accuracy: 0.6223\n",
      "Epoch 9/30\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1166 - accuracy: 0.6223\n",
      "Epoch 10/30\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1163 - accuracy: 0.6223\n",
      "Epoch 11/30\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1160 - accuracy: 0.6223\n",
      "Epoch 12/30\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1157 - accuracy: 0.6223\n",
      "Epoch 13/30\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1155 - accuracy: 0.6223\n",
      "Epoch 14/30\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1152 - accuracy: 0.6223\n",
      "Epoch 15/30\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1150 - accuracy: 0.6223\n",
      "Epoch 16/30\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1147 - accuracy: 0.6223\n",
      "Epoch 17/30\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1146 - accuracy: 0.6223\n",
      "Epoch 18/30\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1144 - accuracy: 0.6223\n",
      "Epoch 19/30\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1142 - accuracy: 0.6223\n",
      "Epoch 20/30\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1141 - accuracy: 0.6223\n",
      "Epoch 21/30\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1139 - accuracy: 0.6223\n",
      "Epoch 22/30\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.1138 - accuracy: 0.6223\n",
      "Epoch 23/30\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1137 - accuracy: 0.6223\n",
      "Epoch 24/30\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1136 - accuracy: 0.6223\n",
      "Epoch 25/30\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1135 - accuracy: 0.6223\n",
      "Epoch 26/30\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1133 - accuracy: 0.6223\n",
      "Epoch 27/30\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1133 - accuracy: 0.6223\n",
      "Epoch 28/30\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1132 - accuracy: 0.6223\n",
      "Epoch 29/30\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1131 - accuracy: 0.6223\n",
      "Epoch 30/30\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.1130 - accuracy: 0.6223\n",
      "37/37 [==============================] - 1s 2ms/step - loss: 0.1269 - accuracy: 0.4617\n",
      "Epoch 1/30\n",
      "74/74 [==============================] - 4s 6ms/step - loss: 0.1200 - accuracy: 0.5395\n",
      "Epoch 2/30\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1200 - accuracy: 0.5422\n",
      "Epoch 3/30\n",
      "74/74 [==============================] - 0s 7ms/step - loss: 0.1198 - accuracy: 0.5422\n",
      "Epoch 4/30\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.1198 - accuracy: 0.5422\n",
      "Epoch 5/30\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1197 - accuracy: 0.5422\n",
      "Epoch 6/30\n",
      "74/74 [==============================] - 0s 7ms/step - loss: 0.1196 - accuracy: 0.5422\n",
      "Epoch 7/30\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1195 - accuracy: 0.5422\n",
      "Epoch 8/30\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1195 - accuracy: 0.5422\n",
      "Epoch 9/30\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1194 - accuracy: 0.5422\n",
      "Epoch 10/30\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1194 - accuracy: 0.5422\n",
      "Epoch 11/30\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1194 - accuracy: 0.5422\n",
      "Epoch 12/30\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1193 - accuracy: 0.5422\n",
      "Epoch 13/30\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1193 - accuracy: 0.5422\n",
      "Epoch 14/30\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1193 - accuracy: 0.5422\n",
      "Epoch 15/30\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1193 - accuracy: 0.5422\n",
      "Epoch 16/30\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1193 - accuracy: 0.5422\n",
      "Epoch 17/30\n",
      "74/74 [==============================] - 0s 7ms/step - loss: 0.1192 - accuracy: 0.5422\n",
      "Epoch 18/30\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.1192 - accuracy: 0.5422\n",
      "Epoch 19/30\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1192 - accuracy: 0.5422\n",
      "Epoch 20/30\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1192 - accuracy: 0.5422\n",
      "Epoch 21/30\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1192 - accuracy: 0.5422\n",
      "Epoch 22/30\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1192 - accuracy: 0.5422\n",
      "Epoch 23/30\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1192 - accuracy: 0.5422\n",
      "Epoch 24/30\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1192 - accuracy: 0.5422\n",
      "Epoch 25/30\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1192 - accuracy: 0.5422\n",
      "Epoch 26/30\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1192 - accuracy: 0.5422\n",
      "Epoch 27/30\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1192 - accuracy: 0.5422\n",
      "Epoch 28/30\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1191 - accuracy: 0.5422\n",
      "Epoch 29/30\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1192 - accuracy: 0.5422\n",
      "Epoch 30/30\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.1192 - accuracy: 0.5422\n",
      "37/37 [==============================] - 1s 2ms/step - loss: 0.1201 - accuracy: 0.5191\n",
      "Epoch 1/30\n",
      "110/110 [==============================] - 3s 6ms/step - loss: 0.1201 - accuracy: 0.5309\n",
      "Epoch 2/30\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1200 - accuracy: 0.5345\n",
      "Epoch 3/30\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1199 - accuracy: 0.5345\n",
      "Epoch 4/30\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1198 - accuracy: 0.5345\n",
      "Epoch 5/30\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.1198 - accuracy: 0.5345\n",
      "Epoch 6/30\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1197 - accuracy: 0.5345\n",
      "Epoch 7/30\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1197 - accuracy: 0.5345\n",
      "Epoch 8/30\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.1196 - accuracy: 0.5345\n",
      "Epoch 9/30\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1196 - accuracy: 0.5345\n",
      "Epoch 10/30\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.1196 - accuracy: 0.5345\n",
      "Epoch 11/30\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1196 - accuracy: 0.5345\n",
      "Epoch 12/30\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1195 - accuracy: 0.5345\n",
      "Epoch 13/30\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1196 - accuracy: 0.5345\n",
      "Epoch 14/30\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1195 - accuracy: 0.5345\n",
      "Epoch 15/30\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1195 - accuracy: 0.5345\n",
      "Epoch 16/30\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1195 - accuracy: 0.5345\n",
      "Epoch 17/30\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1195 - accuracy: 0.5345\n",
      "Epoch 18/30\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1195 - accuracy: 0.5345\n",
      "Epoch 19/30\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1195 - accuracy: 0.5345\n",
      "Epoch 20/30\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1195 - accuracy: 0.5345\n",
      "Epoch 21/30\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1195 - accuracy: 0.5345\n",
      "Epoch 22/30\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1195 - accuracy: 0.5345\n",
      "Epoch 23/30\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1195 - accuracy: 0.5345\n",
      "Epoch 24/30\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.1195 - accuracy: 0.5345\n",
      "Epoch 25/30\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1195 - accuracy: 0.5345\n",
      "Epoch 26/30\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1195 - accuracy: 0.5345\n",
      "Epoch 27/30\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1195 - accuracy: 0.5345\n",
      "Epoch 28/30\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1195 - accuracy: 0.5345\n",
      "Epoch 29/30\n",
      "110/110 [==============================] - 1s 5ms/step - loss: 0.1195 - accuracy: 0.5345\n",
      "Epoch 30/30\n",
      "110/110 [==============================] - 1s 6ms/step - loss: 0.1195 - accuracy: 0.5345\n",
      "37/37 [==============================] - 1s 2ms/step - loss: 0.1179 - accuracy: 0.5792\n",
      "Epoch 1/30\n",
      "147/147 [==============================] - 4s 7ms/step - loss: 0.1200 - accuracy: 0.5430\n",
      "Epoch 2/30\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1197 - accuracy: 0.5457\n",
      "Epoch 3/30\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1195 - accuracy: 0.5457\n",
      "Epoch 4/30\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1194 - accuracy: 0.5457\n",
      "Epoch 5/30\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1193 - accuracy: 0.5457\n",
      "Epoch 6/30\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1192 - accuracy: 0.5457\n",
      "Epoch 7/30\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1191 - accuracy: 0.5457\n",
      "Epoch 8/30\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1191 - accuracy: 0.5457\n",
      "Epoch 9/30\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1191 - accuracy: 0.5457\n",
      "Epoch 10/30\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1190 - accuracy: 0.5457\n",
      "Epoch 11/30\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1190 - accuracy: 0.5457\n",
      "Epoch 12/30\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1190 - accuracy: 0.5457\n",
      "Epoch 13/30\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1190 - accuracy: 0.5457\n",
      "Epoch 14/30\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1190 - accuracy: 0.5457\n",
      "Epoch 15/30\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1190 - accuracy: 0.5457\n",
      "Epoch 16/30\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1190 - accuracy: 0.5457\n",
      "Epoch 17/30\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1190 - accuracy: 0.5457\n",
      "Epoch 18/30\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1190 - accuracy: 0.5457\n",
      "Epoch 19/30\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1190 - accuracy: 0.5457\n",
      "Epoch 20/30\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1190 - accuracy: 0.5457\n",
      "Epoch 21/30\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1190 - accuracy: 0.5457\n",
      "Epoch 22/30\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1190 - accuracy: 0.5457\n",
      "Epoch 23/30\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1190 - accuracy: 0.5457\n",
      "Epoch 24/30\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1190 - accuracy: 0.5457\n",
      "Epoch 25/30\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1190 - accuracy: 0.5457\n",
      "Epoch 26/30\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1190 - accuracy: 0.5457\n",
      "Epoch 27/30\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1190 - accuracy: 0.5457\n",
      "Epoch 28/30\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1190 - accuracy: 0.5457\n",
      "Epoch 29/30\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1190 - accuracy: 0.5457\n",
      "Epoch 30/30\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 0.1190 - accuracy: 0.5457\n",
      "37/37 [==============================] - 1s 2ms/step - loss: 0.1156 - accuracy: 0.6148\n",
      "Epoch 1/30\n",
      "184/184 [==============================] - 4s 6ms/step - loss: 0.1199 - accuracy: 0.5437\n",
      "Epoch 2/30\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1195 - accuracy: 0.5595\n",
      "Epoch 3/30\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1191 - accuracy: 0.5595\n",
      "Epoch 4/30\n",
      "184/184 [==============================] - 1s 6ms/step - loss: 0.1189 - accuracy: 0.5595\n",
      "Epoch 5/30\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1187 - accuracy: 0.5595\n",
      "Epoch 6/30\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1186 - accuracy: 0.5595\n",
      "Epoch 7/30\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1185 - accuracy: 0.5595\n",
      "Epoch 8/30\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1184 - accuracy: 0.5595\n",
      "Epoch 9/30\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1183 - accuracy: 0.5595\n",
      "Epoch 10/30\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1183 - accuracy: 0.5595\n",
      "Epoch 11/30\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1183 - accuracy: 0.5595\n",
      "Epoch 12/30\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1183 - accuracy: 0.5595\n",
      "Epoch 13/30\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1182 - accuracy: 0.5595\n",
      "Epoch 14/30\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1182 - accuracy: 0.5595\n",
      "Epoch 15/30\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1182 - accuracy: 0.5595\n",
      "Epoch 16/30\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1182 - accuracy: 0.5595\n",
      "Epoch 17/30\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1182 - accuracy: 0.5595\n",
      "Epoch 18/30\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1182 - accuracy: 0.5595\n",
      "Epoch 19/30\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1182 - accuracy: 0.5595\n",
      "Epoch 20/30\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1182 - accuracy: 0.5595\n",
      "Epoch 21/30\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1182 - accuracy: 0.5595\n",
      "Epoch 22/30\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1182 - accuracy: 0.5595\n",
      "Epoch 23/30\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1182 - accuracy: 0.5595\n",
      "Epoch 24/30\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1182 - accuracy: 0.5595\n",
      "Epoch 25/30\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1182 - accuracy: 0.5595\n",
      "Epoch 26/30\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1182 - accuracy: 0.5595\n",
      "Epoch 27/30\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1182 - accuracy: 0.5595\n",
      "Epoch 28/30\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1182 - accuracy: 0.5595\n",
      "Epoch 29/30\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1182 - accuracy: 0.5595\n",
      "Epoch 30/30\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 0.1182 - accuracy: 0.5595\n",
      "37/37 [==============================] - 1s 2ms/step - loss: 0.1217 - accuracy: 0.5055\n"
     ]
    }
   ],
   "source": [
    "X = KerasClassifier(build_fn=createLSTMModel,batch_size = batch, epochs = EPO,loss= LOSS,optimizer= Opt,activation=act)\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "cv_results=cross_val_score(X,X_train_LSTM,y_train,cv=tscv,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "59658d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for each folder: [0.46174863 0.5191257  0.57923496 0.61475408 0.50546449]\n",
      "\n",
      "Accuracy for each folder: 0.5360655725002289\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nAccuracy for each folder: {cv_results}\")\n",
    "print(f\"\\nAccuracy for each folder: {cv_results.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e2c057",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
